[
  {
    "objectID": "TR - Yahtzee MCTS.html",
    "href": "TR - Yahtzee MCTS.html",
    "title": "Title",
    "section": "",
    "text": "Lightweight MCTS-based autonomous agent for Yahtzee"
  },
  {
    "objectID": "TR - Yahtzee MCTS.html#mcts-algorithm",
    "href": "TR - Yahtzee MCTS.html#mcts-algorithm",
    "title": "Title",
    "section": "MCTS algorithm",
    "text": "MCTS algorithm\nMonte Carlo Tree Search (MCTS) is a model-free, online planning method. The algorithm explores the decision space by building a search tree in a sequential manner. MCTS involve four phases in its execution, that are repeated until the computational budget is exhausted. The state-action space and the transition probability matrix are represented under the form of a graph.\n\nSelection\n\nStarting from the root node, which is the current state of the MDP, the algorithm select child nodes in the tree until a leaf node is reached. The child selection is performed according to a selection policy. In our case we use the well-known UCT selection policy \\[\\arg \\max_{a \\in A(s)}\\bigg(\\bar{X}(s,a) + C_p\\sqrt{\\frac{log(N(s))}{N(s,a)}}\\bigg)\\] Where :\n\n\\(\\bar{X}(s,a)\\) the average reward after taking action \\(a\\) in state \\(s\\)\n\\(N(s)\\) the number of visits to state \\(s\\)\n\\(N(s,a)\\) the number of times action \\(a\\) has been selected from state \\(s\\)\n\\(C\\) the exploration parameter (can be adjusted to encourage/discourage exploration)\n\n\nExpansion\n\nIf the selected node is a non-terminal state and not fully expanded (meaning not all possible actions have been explored), a child node is added to the tree, representing one possible future states \\(s'\\) resulting from an available action \\(a \\in A(s)\\). We then switch to the child node and repeat the expansion procedure.\n\nSimulation (rollout)\n\nFrom the child node, simulate random trajectories using a default policy (in our case, a random action selection policy) until a terminal state is reached.\n\nBackpropagation\n\nAfter the simulation is done, the reward obtained is propagated back up the tree to update the nodes and actions involved in the selection and expansion phases.\nThe updates are made using the following steps for each node visited in the path from the leaf node to the root :\n\nIncrement the visit count \\(N(s,a)\\) for the action \\(a\\) taken at state \\(s\\)\nUpdate the average reward \\(\\bar{X}(s,a)\\) for the action \\(a\\) at state \\(s\\) as follows : \\[\\bar{X} (s,a) \\leftarrow \\bar{X}(s,a) + \\frac{1}{N(s,a)}\\big(r - \\bar{X}(s,a)\\big)\\]\n\n\nAction selection\n\nOnce we have exhausted our computational budget the simulation stops and we select the action that have the highest value \\[\\arg \\max_{a\\in A(s)} \\bar{X}(s_0,a)\\]"
  },
  {
    "objectID": "TR - Yahtzee MCTS.html#implementation",
    "href": "TR - Yahtzee MCTS.html#implementation",
    "title": "Title",
    "section": "Implementation",
    "text": "Implementation\nThe game engine and the Monte Carlo Tree Search (MCTS) algorithm for Yahtzee have been developed in both Python and JavaScript to provide flexibility in deployment and testing. The Python version was used primarily during the research phase, while the JavaScript version was developed later, for integration into the web application.\nBoth implementations are open-source, the link to the repository containing their respective source code can be found in Appendix.\nBoth of them are similar in terms of logic and sequence only minor differences due to language-specific features and integration need (i.e.: using web workers for MCTS computation in JS version to avoid blocking the UI). In this section we will discuss mainly of the JavaScript implementation and its integration in the web application while in the Results section describe experiments conducted using the Python version.\nFeatures\nThe web application have two modes : AI opponent and AI assistant. In AI opponent mode, the player face the AI agent in a game of Yahtzee. In AI assistant mode, the player plays alone but benefits from advices coming from the AI agent.\nAI assistant provide the player with information such as:\n\nThe mean state-action value \\(\\hat{X}(s,a)\\)\nThe standard error of the mean state-action value\nThe sample standard deviation of the state-action values\nThe sample size \\(n\\), corresponding number of time this action has been sampled during MCTS\nAn histogram of the expected final score conditioned on the current state \\(s\\) and the selected action \\(a\\)\n\nNote : The mean state-action value here is conditioned to following the policy determined by the MCTS algorithm"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bienvenue !",
    "section": "",
    "text": "Je m‚Äôappelle Yacine BEKKA, bienvenue sur mon site personel !\nJe suis un expert en gestion des donn√©es, dipl√¥m√© de l‚ÄôUniversit√© du Colorado en data science. Au cours des huit derni√®res ann√©es, j‚Äôai accompagn√© diverses organisations dans la cr√©ation de valeur ajout√©e gr√¢ce √† une meilleure gestion de leurs donn√©es. J‚Äôai travaill√© sur des sujets vari√©s tels que la mise en place de logiciels de gestion des donn√©es de r√©f√©rence (MDM), la gestion de la qualit√© des donn√©es, la gouvernance des donn√©es, et bien d‚Äôautres, au sein de multiples secteurs d‚Äôactivit√© (web, assurances, banque d‚Äôaffaires, agroalimentaire, ferroviaire, etc.).\nFort de ma formation et de mes exp√©riences professionnelles, j‚Äôoffre des services de conseil aux organisations, principalement dans les domaines de la gouvernance des donn√©es, de la gestion des donn√©es, de l‚Äôarchitecture des donn√©es, et de la gestion de la qualit√© des donn√©es.\nJe publie du contenu original que vous pouvez retrouver ici et sur mes diff√©rents r√©seaux sociaux. Dans mon temps libre, je travaille √©galement sur divers projets (logiciels open source, contenu long-format, recherche), que vous pouvez √©galement consulter sur ce site.\n\n\n\n\nMise en ligne du blog ! (09/2024)\nMise en ligne du projet ‚ÄúAgent autonome pour le jeu de Yathzee‚Äù (09/2024)\nGuide to Data ROI 2e √©dition, en cours d‚Äô√©criture (2024/2025)"
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Bienvenue !",
    "section": "",
    "text": "Je m‚Äôappelle Yacine BEKKA, bienvenue sur mon site personel !\nJe suis un expert en gestion des donn√©es, dipl√¥m√© de l‚ÄôUniversit√© du Colorado en data science. Au cours des huit derni√®res ann√©es, j‚Äôai accompagn√© diverses organisations dans la cr√©ation de valeur ajout√©e gr√¢ce √† une meilleure gestion de leurs donn√©es. J‚Äôai travaill√© sur des sujets vari√©s tels que la mise en place de logiciels de gestion des donn√©es de r√©f√©rence (MDM), la gestion de la qualit√© des donn√©es, la gouvernance des donn√©es, et bien d‚Äôautres, au sein de multiples secteurs d‚Äôactivit√© (web, assurances, banque d‚Äôaffaires, agroalimentaire, ferroviaire, etc.).\nFort de ma formation et de mes exp√©riences professionnelles, j‚Äôoffre des services de conseil aux organisations, principalement dans les domaines de la gouvernance des donn√©es, de la gestion des donn√©es, de l‚Äôarchitecture des donn√©es, et de la gestion de la qualit√© des donn√©es.\nJe publie du contenu original que vous pouvez retrouver ici et sur mes diff√©rents r√©seaux sociaux. Dans mon temps libre, je travaille √©galement sur divers projets (logiciels open source, contenu long-format, recherche), que vous pouvez √©galement consulter sur ce site."
  },
  {
    "objectID": "index.html#mon-actu",
    "href": "index.html#mon-actu",
    "title": "Bienvenue !",
    "section": "",
    "text": "Mise en ligne du blog ! (09/2024)\nMise en ligne du projet ‚ÄúAgent autonome pour le jeu de Yathzee‚Äù (09/2024)\nGuide to Data ROI 2e √©dition, en cours d‚Äô√©criture (2024/2025)"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Pr√©sentation : Le probl√®me des strat√©gies data en 2022\n\n\n1 min\n\n\n\nSep 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData management buzzword\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData quality rules\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat NOT to do for improving data quality\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow to explain the value of data to your colleagues\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData VS Information\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData management jargon\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData in PR vs Data in Reality\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPersuade your boss/team about the value of your projects\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nProbl√®me de qualit√© de donn√©es et d√©sastre op√©rationel √† la NASA\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLa data gouvernance comme les antibiotiques, c‚Äôest pas automatique !\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nLe pire ennemi du professionel de la data\n\n\n3 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData quality target level\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContr√¥le de qualit√© et probl√®mes de qualit√©s de donn√©es\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDimensions de la qualit√©s de donn√©es\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC‚Äôest quoi la data gouvernance ?\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nStrat√©gie data : Objectifs vs Moyens\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData flow map\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nC‚Äôest quoi un data manager ?\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCr√©er de l‚Äôint√©r√™t pour un projet data\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôimportance de la clart√© dans les projets data\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData quality dimensions\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nContr√¥le de qualit√© de donn√©es d√©terministe vs probabiliste\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôimportance de s‚Äôattaquer au causes racines de la non-qualit√©\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n4 livres √† lire sur la gestion de la qualit√© de donn√©es\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nL‚Äôiceberg de la data quality\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n3 d√©finitions pour mieux g√©rer ses donn√©es d‚Äôentreprises\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n4 frameworks de gestion de la qualit√© de donn√©es √† connaitre !\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 frameworks de gestion de la qualit√© de donn√©es √† connaitre !\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSix sigma et qualit√© de donn√©es, l‚Äôerreur classique\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n3 m√©thodes pour calculer un indice de qualit√© des donn√©es\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDialogue fictif entre un CDO et un CEO‚Ä¶\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData quality management process\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrust but verify\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nValeur financi√®re d‚Äôune donn√©es\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nStandard de qualit√© des donn√©es\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nMeme business case quantitatif\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nModel-as-a-service\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nValorisation des donn√©es\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPr√©valence, d√©tection et faux positif\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData-as-an-asset\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCarousel KPI Tree\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCarousel VEIPPP\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBusiness drivers of data quality management\n\n\n3 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCarousel VEII\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCarousel VEIP\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCarousel Esp√©rance et decision\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCarousel Simulation monte carlo\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSlides - Data quality introduction\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSlides - D√©marche de gestion de la qualit√© des donn√©es\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSlides - Standard de qualit√© des donn√©es\n\n\n1 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEtude de cas : Gestion de la qualit√© de donn√©es chez le Groupe SeLoger\n\n\n9 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDealing with duplicates\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRules-based DQ control vs ML/AI based DQ control\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n5 practical tips for better quality management\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nData reliability\n\n\n2 min\n\n\n\nAug 28, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/post_8.html",
    "href": "blog/post_8.html",
    "title": "5 practical tips for better quality management",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-datastrategy-datamanagement-activity-7026086062946963456-FgQ3?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 31 Jan 2023\n\nGet your data quality under control with those 5 practical tips ‚¨áÔ∏è\n‚û° Create the business case for hashtag#dataquality\nData quality is not a goal by itself, it is a means to an end. To convince management and ensure their support you need to demonstrate why data quality matters for the company and how it will contribute to the business strategy.\nWhile it can be difficult to show a quantitative ROI at the start, you can always start by a qualitative business case (check out my post on 4 business drivers of data quality here : https://lnkd.in/eYixnUyu)\n‚û° Start by known pain points\nTargeting known pain points is an easy way to create adherence around your data quality management process.\nIf by the implementation of the process you are able to solve or at least draw a clear view of the root causes, the effort for correction and the business impacts, you will demonstrate the added value of data quality to your company.\n‚û° Iterate implementation by business terms\nIf you cannot implement data quality monitoring for all your data (which is often the case), I recommend working by iteration, defining the scope by business terms.\nIn my experience, it is the best way to scope your iterations based on company priority as business terms are easily relatable and can be linked to known pain points and company strategy\n‚û° Evaluate criticality and business impact of issues not controls\nNo one cares about the data quality controls, everybody cares about data quality issues. In most of the cases controls are quite cheap to perform in terms of money and effort.\nWhat is costly is the resolution of data quality issues, it is also where the business impact(s) can be evaluated more precisely\n‚û° Communicate regularly, show the value\nRegular exchange on the current level of data quality, data quality issues and their resolution should be done with data consumers, data producers and business SMEs.\nOnce you have some, data quality success stories should be shared as much as possible in the company, especially to management. Don‚Äôt hesitate to do the ‚Äúpromotion‚Äù of data quality management and the added value that it brings."
  },
  {
    "objectID": "blog/post_6.html",
    "href": "blog/post_6.html",
    "title": "Dealing with duplicates",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-datamanagement-duplicate-activity-7021904253229137921-NYTk?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 19 Jan 2023\n\nWe have all encountered duplicate hashtag#data in the course of our careers, let‚Äôs see how we can deal with it ‚¨áÔ∏è\nü§î What is a duplicates\nIn the context of enterprise hashtag#datamanagement, we can think of hashtag#duplicate data as a redundant representation of a business object (customer, invoice, material, etc.). An example with a customer referential might look like this :\nCustomer ID = 1 -&gt; Customer Name = Jane, Doe -&gt; Customer Status = Active Customer ID = 365 -&gt; Customer Name = Jan Doe -&gt; Customer Status = Payment Default Customer ID = 1455 -&gt; Customer Name = JaneDoe -&gt; Customer Status = Active\nüîé Identify duplicates\nTo ensure that our data is of high quality, we need to make sure that there is no redundant representation, especially when there is conflicting information. The main difficulty is that duplicates can be hard to identify depending on context and initial data quality.\nIn some cases, a simple deterministic check (whether records are duplicates for sure) may suffice, e.g., an exact match on all or a subset of attributes. In other cases, probabilistic checking (is it likely that these records are duplicates) is required (string edit distance comparison, phonetic comparison, combination of multiple methods, etc.).\nüöß Prevent duplicates\nUsing a unique identifier for our business objects is the first step in properly managing duplicates. Even though the unique identifier ID does not directly prevent the creation of duplicates, it enables unique identification of records, which is a prerequisite for identifying duplicates.\nAn efficient way to prevent duplicates is to include a ‚Äúmatching‚Äù step (which can be manual or automated) in the creation process.\nü™õ Correct duplicates\nCorrecting duplicates is a complex process and requires several steps : - Identification (match duplicate records) - Grouping (cluster duplicates together) - Merging (keep the fittest record)\nDepending on the data and context, you may also need to manage the transfer of other business objects linked with the deduplicated business object. Full traceability of the correction process is also a best practise.\nhashtag#dataquality"
  },
  {
    "objectID": "blog/post_57.html",
    "href": "blog/post_57.html",
    "title": "Etude de cas : Gestion de la qualit√© de donn√©es chez le Groupe SeLoger",
    "section": "",
    "text": "Date originale de publication : 31 mars 2022"
  },
  {
    "objectID": "blog/post_57.html#introduction",
    "href": "blog/post_57.html#introduction",
    "title": "Etude de cas : Gestion de la qualit√© de donn√©es chez le Groupe SeLoger",
    "section": "Introduction",
    "text": "Introduction\nGroupe Seloger est le groupe leader des portails immobiliers en France. Le groupe poss√®de notamment les marques SeLoger, LogicImmo, Meilleurs Agents, etc\nLa qualit√© des donn√©es est tr√®s importante pour le groupe √©tant donn√© que leur business model est √©troitement li√© aux donn√©es. En tant que portail d‚Äôannonces immobili√®res, il est d‚Äôune importance majeur de servir des donn√©es de la plus haute qualit√© au utilisateurs du portail, sur les biens disponibles mais √©galement pour leurs clients du groupe (principalement des agences immobili√®res), de pouvoir fournir des statistiques pr√©cises et de qualit√© sur les interactions des utilisateurs sur les annonces. La qualit√© des donn√©es est √©galement un facilitateur majeur d‚Äôinnovation pour le groupe car elle impacte la capacit√© √† d√©velopper des nouveaux produits/fonctionnalit√©s telle qu‚Äôun moteur de recommandations bas√© sur les pr√©f√©rences des utilisateurs.\nNotre mission consiste √† impl√©menter, en partant de z√©ro, un processus de gestion de la qualit√© des donn√©es pour la plateforme de donn√©es du groupe (h√©berg√©e sur Amazon AWS) en collaboration avec les √©quipes du d√©partement Data."
  },
  {
    "objectID": "blog/post_57.html#challenges",
    "href": "blog/post_57.html#challenges",
    "title": "Etude de cas : Gestion de la qualit√© de donn√©es chez le Groupe SeLoger",
    "section": "Challenges",
    "text": "Challenges\n\nImportant volume et grande vari√©t√© de donn√©es collect√©es chaque jour dans la plateforme de donn√©es (150+ jeux de donn√©es allant de 10-15M √† 20G entr√©es, allant du r√©f√©rentiel clients au interactions des utilisateurs sur les portails)\nFaible maturit√© et culture sur la gouvernance des donn√©es et la gestion de la qualit√© des donn√©es dans le groupe\nFaible implication initiales du ‚Äúm√©tiers‚Äù, interlocuteurs venant principalement des √©quipes IT/Data\nLes donn√©es de la plateforme sont utilis√©es par diff√©rents ‚Äúconsommateurs‚Äù internes pour des usages vari√©s, d√©finition de la qualit√© variant √©galement selon les usages/interlocuteurs\nPas de ressources d√©di√©s √† la gestion de la qualit√© de donn√©es, n√©cessit√© de s‚Äôappuyer sur les √©quipes et outils existants\nD√ª √† l‚Äôimportant volume de donn√©es et √† l‚Äôinfrastructure technique, la reprise de donn√©es ainsi que la rem√©diation des causes racines peut n√©cessiter des co√ªts et des efforts √©lev√©s"
  },
  {
    "objectID": "blog/post_57.html#solution",
    "href": "blog/post_57.html#solution",
    "title": "Etude de cas : Gestion de la qualit√© de donn√©es chez le Groupe SeLoger",
    "section": "Solution",
    "text": "Solution\nAfin de d√©passer ces difficult√©s et livrer les r√©sultats demand√©s, nous avons utilis√© le Data Quality Launchpad, notre m√©thodologie pour acc√©l√©rer votre transformation digitale et r√©duire vos d√©chets op√©rationnels en rendant votre organisation autonome pour g√©rer et am√©liorer de fa√ßon continue la qualit√© de vos donn√©es.\n\nIdentify\n\nPour cette premi√®re √©tape, nous √©changeons avec les √©quipes data pour d√©finir ensemble quelles sont les exigences en termes de qualit√© de donn√©es. Etant donn√© le nombre √©lev√© de jeux de donn√©es √† couvrir et le fait que nous n‚Äôayons pas acc√®s √† des interlocuteurs ‚Äúm√©tiers‚Äù nous avons utilis√© une approche de type g√©n√©rique/sp√©cifique pour la d√©finition des standards de qualit√© de donn√©es (un standard de qualit√© de donn√©es est la collection des r√®gles applicable √† un jeux de donn√©es)\nLe standard de qualit√© g√©n√©rique est con√ßu pour √™tre applicable √† l‚Äôensemble des jeux de donn√©es et les standards sp√©cifiques sont eux d√©di√©s √† un jeux de donn√©es en particulier. Cette approche nous permet de couvrir l‚Äôensemble des jeux de donn√©es avec le standard g√©n√©rique mais avec une pr√©cision amoindri (d√ª √† la g√©n√©ricit√© du standard) et un effort de sp√©cification faible alors que les standards sp√©cifiques sont plus pr√©cis mais n√©cessite plus d‚Äôimplication des interlocuteurs ‚Äúm√©tiers‚Äù\nUne fois les standards de qualit√© d√©finis et formalis√©s, nous d√©rivons ensuite les indicateurs de qualit√© associ√©s et nous effectuons les mesures initiales de qualit√©. Nous avons ensuite analys√© et pr√©sent√© ces mesures au ‚Äúdata consumers‚Äù (collaborateurs utilisant ce jeux de donn√©es en particulier). Comme dans la plupart des organisations, les probl√®mes de qualit√© de donn√©es sont souvent cach√©s ou mal d√©finis. Avec cette premi√®re √©tape nous avons d√©couvert plusieurs probl√®mes de qualit√© √† fort impact que nous avons pr√©sent√©s de fa√ßon factuel. Les ‚Äúdata consumers‚Äù ont √©t√© tr√®s surpris par certaines de ces d√©couvertes et nous ont aid√©s √† √©valuer les impacts, prioriser les diff√©rents probl√®mes et g√©n√©rer de l‚Äôint√©r√™t autour de la qualit√© de donn√©es.\n\nImprove\n\nDans le Groupe SeLoger, les √©quipes data travaillent de mani√®re tr√®s autonome, en suivant la m√©thode Agile ‚Äúby-the-book‚Äù. Afin de s‚Äôappuyer sur les ressources, les outils et les modes de travail d√©j√† en place dans le groupe, nous avons int√©gr√© les diff√©rentes activit√©s de notre m√©thodologie de gestion de la qualit√© de donn√©es avec le processus actuel de gestion des donn√©es du groupe en r√©partissant les responsabilit√©s sur les r√¥les existants. Nous accompagnons et aidons √©galement √† l‚Äôadoption de ces nouvelles t√¢ches aupr√®s des diff√©rents collaborateurs via des sessions de formation et la r√©daction de proc√©dures op√©rationnelles normalis√©es.\nUne fois les r√¥les et responsabilit√©s d√©finis, nous nous sommes concentr√©s sur l‚Äôinvestigation des causes racines pour les probl√®mes de data quality ayant la priorit√© la plus √©lev√©s. Pour cela, nous commen√ßons par lister les diff√©rentes hypoth√®ses de causes racine et nous v√©rifions et testons ensuite la validit√© de ces hypoth√®ses par ordre de probabilit√©. Ce travail n√©cessite l‚Äôimplication de plusieurs √©quipes √† l‚Äôint√©rieur et √† l‚Äôext√©rieur du departement Data. L‚Äôint√©r√™t g√©n√©r√© par la d√©couvertes de ces probl√®mes nous a aid√© √† impliquer ces diff√©rentes √©quipes, nous avons aussi bien distinguer la phase d‚Äôidentification des causes racines et leur r√©solution, en nous concentrant d‚Äôabord uniquement sur l‚Äôidentification.\nApr√®s avoir d√©termin√© les causes racines des probl√®mes de qualit√© √† haute priorit√©, nous avan√ßons vers la phase de solution et d‚Äôanalyse de co√ªts-b√©n√©fices afin d‚Äôarbitrer s‚Äôil est pertinent de corriger la cause racine ou non. Dans cette √©tude de cas, certains probl√®mes de qualit√© avaient un tel impact que les b√©n√©fices d√©passaient largement les co√ªts mais pour d‚Äôautres ce n‚Äô√©tait pas le cas. Dans cette situation, nous avons d√©finis des solutions alternatives qui, bien que non-optimales, permettent de pr√©venir les futurs probl√®mes autant que possible.\n\nCommunicate\n\nPour la communication, nous concentrons nos efforts sur deux axes:\nCommunication sur les aspects op√©rationnels (niveaux actuels de qualit√©s de donn√©es, statut de r√©solution des probl√®mes de qualit√©, alertes de la part des ‚Äúconsommateurs‚Äù de donn√©es) via les notice de qualit√© de donn√©es\nCommunication au management et de fa√ßon plus large, √† l‚Äôensemble de la soci√©t√© (‚Äúsuccess stories‚Äù de la qualit√© de donn√©es) via la Data Quality Newsletter\nPour les notices de qualit√© de donn√©es nous publions des notices, disponibles pour l‚Äôensemble des collaborateurs utilisant ces donn√©es. Pour cela nous utilisons Confluence (l‚Äôoutil utilis√© par les √©quipes Data pour leur site web interne contenant la documentation relatives aux jeux de donn√©es) ainsi que les d√©mo de sprint. De cette mani√®re nous pouvons partager les informations op√©rationnelles sur la qualit√© des donn√©es et recevoir des feedbacks de la part des collaborateurs en ‚Äúlive‚Äù et sur ‚Äúpapier‚Äù.\nPour la Newsletter, nous utilisons Slack √©tant donn√© que c‚Äôest l‚Äôoutil de communication principal au sein du groupe. Les diff√©rences avec les notices de qualit√© sont le contenu (moins op√©rationnels, plus orient√© ‚Äúb√©n√©fices‚Äù), la p√©riodicit√© de publication (newsletter est publi√© moins souvent que les notices) ainsi que le format (plus court et moins exhaustif que les notices)\n\nIterate\n\nA ce stade, l‚Äôorganisation est d√©j√† autonome en termes de gestion de la qualit√© de donn√©es, la mission s‚Äôoriente donc vers l‚Äôam√©lioration continue et la gestion de la qualit√© des donn√©es sur le long-terme\nGr√¢ce au gain de maturit√© et l‚Äôint√©r√™t g√©n√©r√© autour de la gestion de la qualit√© de donn√©es nous avons eu une plus grande implication du management et des collaborateurs ‚Äúm√©tiers‚Äù. Ceci nous a permis de retravailler certains des standards de qualit√© afin de les rendre encore plus pr√©cis, ce qui √† ensuite men√© √† la d√©couverte de nouveaux probl√®mes de qualit√©.\nPour ces nouveaux probl√®mes, nous suivons donc le processus de gestion de la qualit√© maintenant en place dans le groupe (d√©crit dans l‚Äô√©tape ‚ÄúImprove‚Äù)\nNous industrialisons √©galement le suivi des indicateurs de qualit√©s de donn√©es en d√©veloppant un outil Python pour formaliser les standards de qualit√©, calculer les indicateurs associ√©s et g√©n√©rer un tableau de bord r√©capitulatif"
  },
  {
    "objectID": "blog/post_57.html#r√©sultats-obtenus",
    "href": "blog/post_57.html#r√©sultats-obtenus",
    "title": "Etude de cas : Gestion de la qualit√© de donn√©es chez le Groupe SeLoger",
    "section": "R√©sultats obtenus",
    "text": "R√©sultats obtenus\n\nMeilleure visibilit√© sur les probl√®mes de qualit√© de donn√©es et les impacts m√©tiers associ√©s\n√âvaluation factuelle du niveau actuel de qualit√© des donn√©es\nD√©finition de la qualit√© claire et partag√©e dans l‚Äôorganisation (‚Äúproducteur‚Äù de donn√©es, √©quipe data et ‚Äúconsommateurs‚Äù de donn√©es)\nProcessus syst√©matique pour r√©soudre les probl√®mes de qualit√© de donn√©es en utilisant les outils et ressources existantes\nOutil configurable et facile d‚Äôutilisation pour suivre l‚Äô√©volution de la qualit√© des donn√©es et g√©n√©rer des graphiques\nAm√©lioration de la qualit√© des donn√©es pour les jeux de donn√©es les plus important de la plateforme (interaction utilisateurs et association aux annonces immobili√®res, adresse-mail utilisateurs et association au crit√®res de recherches)\nRapport r√©guliers et publication de notice de qualit√© de donn√©es pour partager les niveaux actuels de qualit√© de donn√©es ainsi que le statut de r√©solution des probl√®mes identifi√©s dans l‚Äôorganisation\nMeilleur utilisations des ressources de l‚Äô√©quipe data gr√¢ce √† la d√©finition claire des r√¥les et responsabilit√©s (plus de nettoyage de donn√©es ‚Äúcach√©‚Äù)\nConfiance accru dans la qualit√© des donn√©es au sein de l‚Äôorganisation\nAutonomie dans la gestion et l‚Äôam√©lioration continue de la qualit√© des donn√©es\n\n\nT√©moignages\n‚ÄúAlors que nous √©tions au niveau 0 de maturit√© sur les sujets Data Quality au sein du p√¥le data du Groupe Se Loger, Yacine a su s‚Äôadapter √† notre contexte et √† nos besoins afin de nous faire progresser.\nTr√®s autonome, mais syst√©matiquement dans la collaboration, il m‚Äôa impressionn√©e par sa rapidit√© √† comprendre notre contexte et √† s‚Äôadapter au mieux √† nos besoins. Ce n‚Äôest pas quelqu‚Äôun qui abandonne au premier obstacle, on peut lui faire confiance pour aller au bout des choses.\nJ‚Äôai appr√©ci√© sa force de proposition, sa proactivit√© et sa p√©dagogie, qui nous ont aid√© √† embarquer les parties prenantes sur l‚Äôinitiative. En plus de √ßa c‚Äôest quelqu‚Äôun qui fait preuve d‚Äôune grande humilit√©, avec un bon esprit d‚Äô√©quipe. En bref, je ne peux que le recommander et serai ravie de collaborer √† nouveau avec lui.‚Äù\nEmanuelle Galet, Product Owner Data chez Groupe Seloger"
  },
  {
    "objectID": "blog/post_55.html",
    "href": "blog/post_55.html",
    "title": "Slides - D√©marche de gestion de la qualit√© des donn√©es",
    "section": "",
    "text": "Vid√©o Youtube : https://youtu.be/SIf8w5Fx6Cc\nDate originale de publication : 28 May 2023"
  },
  {
    "objectID": "blog/post_53.html",
    "href": "blog/post_53.html",
    "title": "Carousel Simulation monte carlo",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_simulation-monte-carlo-activity-7075019156529537024-KHvE?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Thu, 15 Jun 2023"
  },
  {
    "objectID": "blog/post_51.html",
    "href": "blog/post_51.html",
    "title": "Carousel VEIP",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_valeur-esp%C3%A9r%C3%A9e-dune-information-parfaite-activity-7077518067353665536-UoTN?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Thu, 22 Jun 2023"
  },
  {
    "objectID": "blog/post_5.html",
    "href": "blog/post_5.html",
    "title": "Business drivers of data quality management",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_4-business-drivers-of-data-quality-activity-7020705759898292224‚ÄìObA?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 16 Jan 2023\n\nWhy does your organization need data quality in the first place ? Let me introduce you to 4 business drivers of data quality management üëá\nüéØ Operational excellence\nImproved hashtag#dataquality leads to more efficiency in your company‚Äôs operations.\nIn a multinational company, data often needs to be collected from multiple sources (ERP, legacy, financial/accounting applications, etc.) for balance sheet calculations. With low data quality, this process becomes a nightmare as you have to check for duplicates, inconsistencies between sources, missing data, anomalies, etc., causing additional costs and delays.\nüß† Better decision making\nHigh-quality data provided in a reliable manner helps in decision making by providing trusted insights and information about the company‚Äôs business.\nThe commercial department of a multinational company decides to perform a simple analysis to find out which customer account accounts for the largest share of revenues. The invoices data are stored in ERP, while the customers (from the trade department‚Äôs point of view) are stored in CRM. If the DQ is low, mapping CRM customers to ERP customers could be difficult (major customer LTD vs.¬†major customer UK vs.¬†major customer). In this case, some of the invoices made with this customer might not be included in the final analysis, which would affect the decisions based on this analysis.\nüöÄ Enable innovation through hashtag#analytics and hashtag#machinelearning\nTo quote SCOTT TAYLOR - The Data Whisperer, the golden rule for data is ‚Äúgarbage in, garbage out.‚Äù Low data quality can prevent companies from leveraging AI and machine learning to stay ahead of the competition.\nExample : an automotive manufacturer wants to develop a new predictive maintenance service (parts replaced just-in-time before of failure), but when they review their service order database, they find that there are a large number of duplicates and missing data. If they use this data ‚Äúas is‚Äù to train an hashtag#AI algorithm, the results will not be very efficient, and likely this service will not see the light of day.\nüíµ Monetization of data\nIn the age of personalized advertising and artificial intelligence, data is now a commodity that can have solid financial value if managed properly. As a business, you generate data and have access to some data sets that are likely unique or very difficult to replicate. If you can provide this regularly and reliably in high quality, it can be a new revenue stream.\nExample: a stockbroker has access to the order flow of his customers. This data is of great value as it can reveal who is buying/selling a particular stock or financial instrument at which moment, and can then be sold to third parties or used by the company itself (subject to laws and regulations). On the other hand, if the data quality is low (duplicate customers, wrong ISIN code/ticker, wrong timestamp, etc.), the value of this data set decreases or even goes to zero‚Ä¶"
  },
  {
    "objectID": "blog/post_48.html",
    "href": "blog/post_48.html",
    "title": "Carousel KPI Tree",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_carousel-kpi-tree-activity-7081504356298027008-brgE?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 03 Jul 2023"
  },
  {
    "objectID": "blog/post_46.html",
    "href": "blog/post_46.html",
    "title": "Pr√©valence, d√©tection et faux positif",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_petite-%C3%A9nigme-pour-la-team-linkedin-un-logiciel-activity-7080424719635607552-UpMc?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Fri, 30 Jun 2023\n\nPetite √©nigme pour la team Linkedin\nUn logiciel de data quality, bas√© un algorithme de d√©tection d‚Äôanomalies, permettant d‚Äôidentifer les probl√®me de qualit√© est √† l‚Äô√©tude‚Ä¶.\nSuite √† des test sur des donn√©es historiques, on sait les choses suivantes :\n\nSur 10 anomalies, 9 sont marqu√©es par le logiciel\nSur 10 entr√©es correctes, 2 sont marqu√©es comme anomalies\n\nLes affirmations ci-dessous sont-elles vraies ? Et pourquoi ?\n\nSi une entr√©e est marqu√©e par le logiciel il y a 90% de probabilit√© que ce soit une anomalie.\nUne entr√©e correcte √† 80% de probabilit√© de ne pas √™tre marqu√©e comme anomalie."
  },
  {
    "objectID": "blog/post_44.html",
    "href": "blog/post_44.html",
    "title": "Model-as-a-service",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataasset-datamanagement-datastrategy-activity-7079337576704159744-KK3n?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 27 Jun 2023\n\nOpenAI, un des meilleurs business mod√®le au monde ?\nLe ‚ÄúModel-as-a-service‚Äù\nOpenAI loue l‚Äôacc√®s √† leur mod√®les pour faire des revenues\nMais √† la diff√©rence de louer un bien immobilier ou une voiture\nLes mod√®les d‚ÄôOpenAI eux : - peuvent √™tre lou√© √† plusieurs clients en m√™me temps - Plus ils sont utilis√©s plus ils vont s‚Äôappr√©cier\nOpenAI est doublement gagnant, les utilisateurs payent pour l‚Äôacc√®s et par leur utilisation, contribuent √† am√©liorer les mod√®les\nD‚Äôautres soci√©t√©s comme Tesla, Google, etc ne donnent pas acc√®s directement au mod√®le mais vendent un produits ou un service ‚Äúon-top‚Äù et b√©n√©ficie du m√™me effet ‚Äúkiss-cool‚Äù\nAutre points √† noter :\n\nCes actifs ne sont pas inscrits au bilan comptable donc pas tax√©s directement\nPlus ils s‚Äôappr√©cient plus il devient difficile pour les concurrents potentiels de rivaliser\n\nT‚Äôen pense quoi ?"
  },
  {
    "objectID": "blog/post_42.html",
    "href": "blog/post_42.html",
    "title": "Standard de qualit√© des donn√©es",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-data-datamanagement-activity-7073962169251291136-6ML_?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 12 Jun 2023\n\nUn √©l√©ment CL√â pour BIEN g√©rer la QUALIT√â DES DONN√âES‚Ä¶.\nLe standard de qualit√©\nEn quoi √ßa consiste ?\nEt bien c‚Äôest l‚Äôensemble des r√®gles de qualit√© de donn√©es ainsi que les indicateurs associ√©s.\nOn va √©crire ces r√®gles avec les producteurs et les consommateurs de donn√©es, en langage naturel.\nL‚Äôid√©e c‚Äôest qu‚Äôavec nos connaissances de la r√©alit√©‚Ä¶\nOnt d√©finissent une liste de r√®gles pour v√©rifier que les donn√©es en sont bien la repr√©sentation\nCe standard est sp√©cifique √† un jeux de donn√©es mais aussi √† un groupe d‚Äôusage de la donn√©es en question\nSi les utilisations de la donn√©es sont tr√®s diff√©rentes, on peut imaginer que les besoins en termes de qualit√© le soit aussi\nDans ce cas, il vaut mieux avoir plusieurs jeux de donn√©es (et donc plusieurs standards) pour s‚Äôaccommoder des diff√©rents besoins."
  },
  {
    "objectID": "blog/post_40.html",
    "href": "blog/post_40.html",
    "title": "Trust but verify",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-datamanagement-trustbutverify-activity-7071734965184393216-1Lmg?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 06 Jun 2023\n\nLa plupart des organisations sur-estiment le niveau de qualit√© de de leur donn√©es\nOn √† tendance √† vouloir croire en la v√©racit√© et l‚Äôexactitude des donn√©es\nDis autrement, les donn√©es sont vraies jusqu‚Äô√† preuve du contraire\nDans une d√©marche de gestion de la qualit√©, on ne peut pas se permettre uniquement de croiser les doigts et d‚Äôesp√©rer que les donn√©es sont bonnes‚Ä¶\nC‚Äôest notre job de v√©rifier !\nEt souvent quand on d√©fini et qu‚Äôon mesure le niveau de qualit√© pour la 1√®re fois\nIl y a souvent des surprises‚Ä¶.\nJ‚Äôai travaill√© pour une soci√©t√© qui s‚Äôest rendu compte que pour deux de ses datasets cl√©s, il manquait la moiti√© des relations\nOu une autre qui avait plus de 30% de doublons dans un r√©f√©rentiel fournisseurs\nAvant la mesure du niveau de qualit√©, personne dans l‚Äôorganisation n‚Äôaurait imagin√© que ce soit le cas‚Ä¶\nOn peut y voir une forme de similarit√© avec la s√©curit√© informatique par exemple\nOn ne peut pas juste esp√©rer que tous les utilisateurs/acteurs seront bienveillants‚Ä¶\nIl faut pr√©voir et tester les diff√©rents sc√©narios, et encore plus ceux qu‚Äôon ne souhaiterais jamais avoir √† affronter"
  },
  {
    "objectID": "blog/post_39.html",
    "href": "blog/post_39.html",
    "title": "Dialogue fictif entre un CDO et un CEO‚Ä¶",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_au-fait-est-ce-que-tu-as-suffisamment-activity-7071372578048618496-iZM8?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 05 Jun 2023\n\nüë®‚Äçüíº: ‚ÄúAu fait, est-ce que tu as suffisamment de budget pour la data quality‚Äù\nüë®‚Äçüíº: ‚ÄúTu es s√ªr ? N‚Äôh√©site pas si tu as besoin de quoi que ce soit, on sait que c‚Äôest un sujet important, tout le Codir est derri√®re toi‚Äù\nJe pense que ces deux phrases n‚Äôont probablement jamais √©t√© prononc√©es par aucun CEO‚Ä¶\nEt peut-√™tre √† juste titre‚Ä¶\nEntre professionnels de la donn√©es, l‚Äôimportance et les b√©n√©fices d‚Äôune bonne qualit√© paraissent √©vident\nMais pour le Codir, la qualit√© de donn√©es n‚Äôest que le sous-sujet d‚Äôun sous-sujet d‚Äôun sous-sujet,‚Ä¶ au sein d‚Äôune probl√©matique g√©n√©rale\nComment g√©rer au mieux l‚Äôorganisation ?\nAvec toutes les consid√©rations que √ßa impliquent\nAlors comment faire pour que des aspects, pourtant critiques comme la qualit√© de donn√©es, ne finissent pas par √™tre n√©glig√©s‚Ä¶\nJe pense qu‚Äôun des gros point faible de la data quality, c‚Äôest la difficult√© de d√©montrer un ROI\nOn conna√Æt tous l‚Äôastuce du business case qualitatif (dont les projets data sont en g√©n√©ral tr√®s friand)\nMais avec le contexte √©conomique actuel,\nAvoir la capacit√© de d√©montrer, de fa√ßon chiffr√©, qu‚Äôune am√©lioration de la qualit√© de donn√©es aura un impact b√©n√©fique r√©el\nC‚Äôest peut-√™tre une des cl√©s pour permettre aux organisations de r√©aliser le potentiel de leur donn√©es."
  },
  {
    "objectID": "blog/post_37.html",
    "href": "blog/post_37.html",
    "title": "Six sigma et qualit√© de donn√©es, l‚Äôerreur classique",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-data-datagovernance-activity-7069560641505619968-MXos?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 31 May 2023\n\nL‚ÄôERREUR √† ne PAS FAIRE si tu veux appliquer la m√©thode Six Sigma √† la DATA QUALITY\nEst-ce que tu as d√©j√† entendu parler de SPC (Statistical Process Control) ?\nPour r√©sumer simplement, √ßa consiste √† utiliser la statistique pour contr√¥ler la stabilit√© d‚Äôun processus.\n√Ä la base d√©velopp√©es pour l‚Äôindustrie, la plupart des m√©thodes de SPC reposent sur les principes suivant :\n‚Ä¢ Dans un processus de fabrication stable, √† entr√©e constante la variabilit√© en sortie va elle aussi √™tre stable. ‚Ä¢ Tout √©cart trop important par rapport √† la moyenne devrait donc √™tre consid√©r√© comme une anomalie potentielle et √™tre investigu√©.\nAvec l‚Äô√©mergence du paradigme ‚Äúdata-as-a-product‚Äù, on pourrait avoir envie de faire la m√™me chose pour nos donn√©es ?\nEt bien OUI et NON‚Ä¶\nNON car beaucoup de gens font l‚Äôerreur de vouloir v√©rifier directement les donn√©es avec ces m√©thodes.\nExemple : Si une valeur du champ X de la table Y est √† +/- 6 √©cart-types alors c‚Äôest une anomalie.\nLe probl√®me c‚Äôest que nos donn√©es ne sont pas uniquement le produit d‚Äôun processus, mais aussi une repr√©sentation de la r√©alit√©.\nEt que l‚Äôon ne sait pas si notre √©chantillon (aka notre dataset) est repr√©sentatif de la population ‚Äúr√©elle‚Äù (ce n‚Äôest peut-√™tre pas un √©chantillon randomis√©).\nNi qu‚Äôil contient des observations ind√©pendantes entre elles.\nPour te donner un exemple, imaginons que tu veuilles mettre en place ce type de contr√¥le sur l‚Äô√¢ge des salari√©s de l‚Äôorganisation.\nTu fais tes calculs et tu te rends compte que l‚Äô√¢ge moyen est de 32 ans, avec +/- 3 ans d‚Äô√©cart-type.\nTu fais tes z-scores pour tous tes employ√©s et tous les employ√©s de +50 ans vont √™tre consid√©r√©s comme des anomalies‚Ä¶.\nCe qui n‚Äôest pas forc√©ment le cas, c‚Äôest peut-√™tre juste des employ√©s plus √¢g√©s que la moyenne.\nEn fait il y a beaucoup d‚Äôautres raisons qui expliquent l‚Äô√©cart qu‚Äôune erreur de qualit√© de donn√©es.\nCe n‚Äôest donc pas une fa√ßon efficace pour v√©rifier la qualit√© des donn√©es.\nEn revanche OUI, il est possible d‚Äôutiliser ce genre de m√©thode pour la DATA QUALITY.\nMais je garde le suspense‚Ä¶ et je te dirai comment exactement dans une de mes prochaines vid√©os !"
  },
  {
    "objectID": "blog/post_35.html",
    "href": "blog/post_35.html",
    "title": "4 frameworks de gestion de la qualit√© de donn√©es √† connaitre !",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_4-framework-de-data-quality-dont-tu-peux-activity-7067386330778882048-p3oD?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Thu, 25 May 2023\n\n4 framework de DATA QUALITY dont tu peux t‚Äôinspirer pour cr√©er le TIEN !\n‚Ä¢ Total Data Quality Management du MIT Information Quality Program\nCon√ßu lors d‚Äôune activit√© de recherche pour d√©finir une th√©orie de la data quality Propose la notion d‚Äôinformation product Les publication du MIT Information Quality (MITIQ) Program sur leur site web sont tr√®s int√©ressante m√™me si plus m√†j\n‚Ä¢ 10 steps Data Quality Framework de Danette McGilvray\nS√ªrement le plus connu, orient√© projet ‚Äúone-shot‚Äù Le mod√®le est pratique et efficace, √©galement un des rare √† aborder l‚Äôaspect communication\n‚Ä¢ Total Information Data Quality Management by Larry English\nCon√ßu initialement pour des projet de datawarehouse ‚ÄúOld but gold‚Äù, une des r√©f√©rences en la mati√®re Mod√®le de co√ªts/b√©n√©fices limit√© en termes de donn√©es mais tr√®s int√©ressant (un des plus d√©taill√© que j‚Äôai vu jusqu‚Äô√† pr√©sent)\nEn bonus, un autre que je connais pas bien mais que auxquels plusieurs ouvrages font r√©f√©rence :\n‚Ä¢ Istat Data Quality Methodology from Italian National Institute of Statistics\nA la particularit√© d‚Äôavoir √©t√© con√ßu pour une administration publique avec plusieurs agences (centrales, locales, p√©riph√©riques) Pour l‚Äôinstant, je n‚Äôen sais pas grand-chose de plus, il faudra creuser par toi-m√™me si √ßa t‚Äôint√©resse\nSi tu connais d‚Äôautres framework de gestion de la qualit√© int√©ressant n‚Äôh√©site pas √† les partager en commentaires !"
  },
  {
    "objectID": "blog/post_33.html",
    "href": "blog/post_33.html",
    "title": "L‚Äôiceberg de la data quality",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-datamanegement-datagovernance-activity-7066661564455505920-2Wds?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 23 May 2023\n\nLes anomalies de la qualit√© de donn√©es viennent rarement seules‚Ä¶\nC‚Äôest en g√©n√©ral le sympt√¥me d‚Äôun probl√®me plus profond avec le SI et/ou les processus m√©tiers\nD‚Äôo√π l‚Äôimportance de ne pas faire de la data quality en silo (champ d‚Äôaction limit√©)\nEt d‚Äôassocier la d√©marche qualit√© √† une gouvernance\nSans quoi tu risque de courir apr√®s les anomalies‚Ä¶"
  },
  {
    "objectID": "blog/post_31.html",
    "href": "blog/post_31.html",
    "title": "L‚Äôimportance de s‚Äôattaquer au causes racines de la non-qualit√©",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-data-datamanagement-activity-7061950506369179648-g9dM?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 10 May 2023\n\nEst-ce que tu connais le point commun entre un MARIN et un DATA QUALITY MANAGER ?\nNon‚Ä¶ ? ü§î\nJe te propose de d√©couvrir le point commun entre r√©parer un bateau qui coule et r√©soudre des probl√®mes de qualit√© de donn√©es ‚¨á\nPour une am√©lioration continue de la qualit√©, je pense qu‚Äôil est n√©cessaire d‚Äôavoir une approche radicale.\nDans le sens ou notre approche doit adresser les causes racines √† l‚Äôorigine des probl√®mes de qualit√©\nEt ne pas juste ‚Äúrester en surface‚Äù\nPour illustrer ce point, j‚Äôaime bien l‚Äôanalogie du bateau‚Ä¶.\nOn imagine qu‚Äôon est sur bateau en mer et que la coque soit perc√©e, le bateau commence donc √† se remplir d‚Äôeau et √† couler\nR√©soudre en ‚Äúfirefighting‚Äù les anomalies et l‚Äô√©quivalent de prendre un seau et de vider l‚Äôeau\nC‚Äôest peut-√™tre n√©cessaire dans certains cas afin d‚Äô√©viter l‚Äôimminence du naufrage\nMais √ßa ne r√©soudra pas le probl√®me sur le long terme\nUne approche plus p√©renne consiste √† chercher la fuite, √† la boucher puis ensuite √† vider l‚Äôeau du bateau\nEt pour la gestion de la qualit√©, l‚Äôapproche est similaire\nIl faudra parfois corriger en urgence certaines anomalies‚Ä¶.\nMais le gros du travail devrait √™tre orient√© vers la r√©solution des causes racines puis la correction des donn√©es"
  },
  {
    "objectID": "blog/post_3.html",
    "href": "blog/post_3.html",
    "title": "Data quality dimensions",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-dama-data-activity-7016309770659766273-1AiP?utm_source=share&utm_medium=member_desktop\nDate originale de publication :\n\nI have stopped using hashtag#dataquality dimensions and you should too ! Here‚Äôs why‚Ä¶ ‚¨á\nCan you really tell the difference between accuracy, consistency and validity dimension without looking at the hashtag#dama DMBOK ? I find this notion a bit confusing and difficult to explain to business people.\nI often see the case where those dimensions are used as a way to define data quality indicators (i.e.¬†: accuracy rate or consistency rate) and usually there is not much clarity on what those indicators mean. The main problem is that interpretation of those dimensions can vary drastically depending on context and the audience.\nIt is more useful to know what the metric represents exactly in plain business terms rather than know that it is the accuracy/consistency/validity/synchronicity/whatever dimensions indicator.\nData quality indicators must be factual, precise, driven by business rules and cannot not rely only on those notions as they are too much subject to interpretation. It must also be easily shareable with people that are not be knowledgeable on those concepts as addressing the root cause(s) might involved virtually anybody in the organization.\nI‚Äôm not saying we should dump data quality dimension but maybe take a step back. Under the assumption that data quality rules are in fact business rules, the data quality indicators should measure if we comply with our business rules. Then data quality dimensions can be used as a way of categorizing our business rules and subsequent data quality indicators but not as the main driver for rules definition.\nTo illustrate that, the reasonability rate of your customer referential most likely doesn‚Äôt ring any bell to your business stakeholders or if it does chances are that the exact meaning is unclear‚Ä¶ at best. On the other hand if you talk about the rate of invoice not associated with a valid customer, the exact meaning is much more perceptible at a glance, which would contribute to a better understanding of data quality by business.\n\nOriginal picture from Andrea Piacquadio on Pexels"
  },
  {
    "objectID": "blog/post_27.html",
    "href": "blog/post_27.html",
    "title": "Cr√©er de l‚Äôint√©r√™t pour un projet data",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_la-technique-secr%C3%A8te-pour-cr%C3%A9er-de-lint%C3%A9r%C3%AAt-activity-7057601855534587904-T8Ga?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Fri, 28 Apr 2023\n\nLa technique secr√®te pour cr√©er de l‚Äôint√©r√™t pour ton projet data üò± !\nEst-ce que tu t‚Äôes d√©j√† retrouv√© en gal√®re de budget ou que tu n‚Äôarrive pas √† cr√©er de l‚Äôint√©r√™t pour ton projet data ?\nC‚Äôest une situation que j‚Äôai moi m√™me rencontr√© comme beaucoup d‚Äôautre je pense üòÅ\nEt peu importe ton niveau de s√©niorit√©, tu vas s√ªrement devoir convaincre des gens de pr√™ter attention √† ce que tu veux faire\nDonc un conseil, sois bien attentif √† ce poste !\nBon alors ce secret‚Ä¶ .\nLa logique est tr√®s simple : Montre la douleur\nSi tu veux cr√©er de l‚Äôint√©r√™t √† coup s√ªr, d√©montre comment ne PAS faire ce que tu propose est douloureux\nPlus douloureux que le statu quo\nOn est plus facilement motiv√© √† √©viter la douleur qu‚Äô√† chercher du plaisir\nSurtout si le ‚Äúplaisir‚Äù (comprendre les b√©n√©fices de ton projet data) requiert des efforts‚Ä¶\nVoil√†, tu connais la technique secr√®te !\nAttention cependant, cette technique est puissante\nTu risques de pas te faire que des amis au passage‚Ä¶\n√Ä utiliser √† tes risques et p√©rils üòâ\nEt surtout √† coupler avec une bonne ‚Äúintelligence de jeu‚Äù"
  },
  {
    "objectID": "blog/post_25.html",
    "href": "blog/post_25.html",
    "title": "Data flow map",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_architecture-dataflow-datamanagement-activity-7056877072584962048-I4VF?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 25 Apr 2023\n\nEst-ce que tu connais ce document SUPER UTILE pour s‚Äôy retrouver dans un SI COMPLEXE mais qui est souvent OUBLI√â ? üòØ\n‚Ä¶\nLa DATA FLOW MAP !\nEn fran√ßais, cartographie des flux de donn√©es, est une repr√©sentation visuelle des √©changes de donn√©es entre les applications d‚Äôune organisation.\nElle pour but de faciliter la compr√©hension des √©changes de donn√©es entre les diff√©rents syst√®mes informatiques de l‚Äôentreprise\nNiveaux de grains (du moins fin au plus fin):\n\nApp-to-App et Process-by-process : Les flux de donn√©es entre applications sont repr√©sent√©s par processus m√©tier\n\n(ex : CRM -&gt; ERP | Sales to Cash).\n\nApp-to-App et Data-by-Data : Les flux de donn√©es entre applications sont repr√©sent√©s donn√©es par donn√©es\n\n(ex : CRM ‚Üí ERP | R√©f√©rentiel client).\n\nApp-to-App et Function-by-Function : Les flux de donn√©es entre applications sont repr√©sent√©s par fonction\n\n(ex : Client CRM ‚Üí ERP | R√©plication journali√®re des nouveaux clients du CRM vers l‚ÄôERP).\nComment cr√©er une cartographie des flux de donn√©es √† partir de z√©ro ?\nNe vise pas la perfection du 1er coup, c‚Äôest impossible d‚Äô√™tre exhaustif et pr√©cis d√®s le d√©part.\nCommence par ce qui est d√©j√† connu et met en perspective les informations recueillies.\nPlan √©tape par √©tape :\n\nClasser par priorit√© toutes les applications g√©r√©es par la DSI.\nPr√©parer un questionnaire pour recueillir les infos dont tu as besoin (application source/cible, donn√©es √©chang√©es, fr√©quence, d√©clenchement, fonction, techno, etc)\nIdentifier les responsables des applications c√¥t√© IT (et si possible, les responsables c√¥t√© m√©tier √©galement).\nOrganiser des ateliers avec chaque responsable d‚Äôapplication pour recueillir des informations sur les flux de donn√©es existants et futurs de leur application.\n√Ä partir des informations recueillies, tu cr√©es les diff√©rents niveaux de cartographie des flux de donn√©es.\n\nL‚Äôobjectif est d‚Äôobtenir rapidement une premi√®re version pour faciliter la suites des discussions sur l‚Äôarchitecture globale"
  },
  {
    "objectID": "blog/post_23.html",
    "href": "blog/post_23.html",
    "title": "C‚Äôest quoi la data gouvernance ?",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_datagovernance-data-activity-7054702754232979456-5ngU?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Thu, 20 Apr 2023\n\nEn vrai c‚Äôest quoi une data gouv‚Äô‚Ä¶ ü§î ?\nApr√®s avoir travaill√© de pr√®s ou de loin sur la gouvernance des donn√©es de 4 soci√©t√©s diff√©rentes au cours des 7 derni√®res ann√©es‚Ä¶\nJe voudrais te partager ma d√©finition ‚Äúpratique‚Äù de la hashtag#datagovernance.\nEn r√©alit√© une gouvernance de donn√©es c‚Äôest :\n\nAvoir une d√©finition claire pour nos donn√©es (savoir ce qu‚Äôelle repr√©sente ces donn√©es !)\nSupporter l‚Äôinterpr√©tation en documentant les r√®gles m√©tiers, les mod√®le de donn√©es, les relations, etc\nAvoir des r√¥les et responsabilit√©s clair sur la gestion des donn√©es l‚Äôentreprise (ce qui veut dire √† minima qu‚Äôil y une personne qui est responsable sur chacune des donn√©es du p√©rim√®tre)\nPermettre l‚Äô√©change et la collaboration autour des donn√©es de l‚Äôentreprise √† travers les diff√©rents domaines via un ‚Äúr√©seau hashtag#data‚Äù\nAvoir un cadre qui permet de maintenir et d‚Äôam√©liorer tous les points d√©crits au-dessus\n\nQu‚Äôest ce que tu en penses ?"
  },
  {
    "objectID": "blog/post_20.html",
    "href": "blog/post_20.html",
    "title": "Contr√¥le de qualit√© et probl√®mes de qualit√©s de donn√©es",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-dataquality-qualitaezdedonnaezes-activity-7051803633595609088-qrnR?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 12 Apr 2023\n\nSi ton process de DATA QUALITY est centr√© principalement sur les CONTR√îLES DE QUALITE, tu as TOUT FAUX !\nCe qui importe VRAIMENT, ce sont les PROBLEME DE QUALITE des donn√©es\nLe nombre et la criticit√© des contr√¥les ne devraient pas √™tre la chose sur laquelle tu te concentre le plus‚Ä¶.\nEvidemment, tu devrais effectuer autant de contr√¥les que n√©cessaire, sinon autant que possible.\nDans la plupart des cas, les contr√¥les de data quality ne co√ªte pas grand-chose (ni en temps ni en euros)\nA moins que tes contr√¥le de qualit√© soient tr√®s sophistiqu√©\nOu que qu‚Äôils soient compl√®tement fait √† la main dans un obscur fichier Excel‚Ä¶.\nCe qui devrait √™tre l‚Äôobsession de chaque data quality manager c‚Äôest les probl√®mes de qualit√© des donn√©es.\nLe nombre de probl√®mes et leur criticit√© sont beaucoup plus importants !\nCar c‚Äôest la r√©solution de ses probl√®mes qui va permettre une am√©liorations de la qualit√©, et non les contr√¥les eux-m√™mes.\nEn fin de compte, les 2 m√©triques qui compte vraiment pour ton processus de gestion de la qualit√© des donn√©es (surtout au d√©but) sont :\n\nLes probl√®mes de qualit√© identifi√©s\nLes probl√®mes de qualit√© r√©solus"
  },
  {
    "objectID": "blog/post_19.html",
    "href": "blog/post_19.html",
    "title": "Le pire ennemi du professionel de la data",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-doublons-datacleansing-activity-7051463824742207488-wuAz?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 11 Apr 2023\n\n\nTous les pros de la data m‚Äôont d√©j√† rencontr√©s au moins une fois dans leur carri√®re‚Ä¶.\nJe viens fausser tes r√©sultats d‚Äôanalyse et cr√©er des anomalies dans tes reporting\n\nQui suis-je‚Ä¶ ?\nUn doublon !\nEt oui les doublons sont une des probl√©matiques majeures de la qualit√© de donn√©es.\nAlors comment faire pour ne pas en avoir (ou du moins en avoir le moins possible) ?\n\nIdentification\n\nIdentifier des doublons c‚Äôest plus un art qu‚Äôune science !\nLa premi√®re √©tape d‚Äôun d√©doublonnage est de ‚Äúcomputer‚Äù toutes les paires possibles (produit cart√©sien du jeu de donn√©es). Puis il faut d√©terminer si chaque paire est un doublon\nC‚Äôest l√† ou √ßa commence √† se corser‚Ä¶\nSelon le niveau d‚Äôexigences, le mod√®le de donn√©es et les r√®gles m√©tiers, la fa√ßon d‚Äôidentifier des doublons ne sera pas la m√™me.\nPour un mod√®le de donn√©es simples, une simple comparaison exacte sur un ou plusieurs attributs peut suffire\nEn revanche pour des donn√©es plus complexes, il faudra surement utiliser des contr√¥les plus avanc√©s\n2 exemples connu :\n\nLa distance de Levenshtein, qui mesure la similarit√© entre deux cha√Ænes de caract√®res\nLe Soundex qui permet de comparer la similarit√© de prononciation entre deux cha√Ænes de caract√®res\n\nOn peut m√™me combiner les diff√©rentes m√©thodes et avoir un score de similarit√© pour chacune.\nIl nous faut ensuite s√©parer les paires en doublons de celles qui n‚Äôen sont pas\nPour √ßa plusieurs m√©thode peuvent-√™tre utilis√©, allant de la plus simple (‚Äùau doigt mouill√©‚Äù) √† des m√©thodes de classification plus complexes (random forest, apprentissage actif, etc)\n\nCorriger\n\nLa prochaine √©tape est le regroupement de nos doublons entre eux avant de choisir l‚Äôentr√©es la plus qualitative.\nLa encore plusieurs m√©thodes peuvent √™tre utiliser pour le groupage, √† d√©finir selon les exigences en termes de qualit√©\nLe plus simple √©tant une approche na√Øve ‚Äî&gt; Si A et B son doublon et B et C sont doublons alors A et C sont doublons\nOn veut √©videmment garder l‚Äôentr√©e qui √† la meilleure qualit√©. Pareil plusieurs mani√®res de faire, la plus simple √©tant de garder l‚Äôentr√©e avec le plus d‚Äôattributs remplis\nUne bonne pratique est de garder un historique complet de l‚Äôop√©ration pour pouvoir revenir en arri√®re en cas de probl√®me.\nIl faut aussi penser √† g√©rer le transfert des autres jeux de donn√©es rattach√©s vers notre jeux de donn√©es d√©doublonn√©es !\n\nPr√©venir\n\nUtiliser un identifiant unique ! M√™me si il ne pr√©vient pas directement des doublons, il permet d‚Äôidentifier chaque entr√©e de fa√ßon √©quivoque et constitue donc un pr√©alable au d√©doublonnage\nL‚Äôimpl√©mentation de contr√¥le de de type ‚Äúmatching‚Äù (qui peut √™tre manuelle ou automatis√©e) pendant ou juste avant la saisie afin de nous assurons que le processus de saisie des donn√©es ne g√©n√®re pas de doublons."
  },
  {
    "objectID": "blog/post_17.html",
    "href": "blog/post_17.html",
    "title": "Probl√®me de qualit√© de donn√©es et d√©sastre op√©rationel √† la NASA",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_saviez-vous-que-la-nasa-%C3%A0-perdu-125m-%C3%A0-cause-activity-7048649012710633473-UQ7G?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 03 Apr 2023\n\nSaviez-vous que la NASA √† PERDU $125M √† cause d‚Äôune MAUVAISE DATA QUALITY ?\nLa data quality n‚Äôest un sujet ‚Äúsexy‚Äù pour tout le monde et peut parfois sembler loin de la r√©alit√© concr√®te.\nJe vais donc vous raconter, comment la NASA √† perdu $125M √† cause d‚Äôune mauvaise qualit√© de donn√©es\nLe 11 d√©cembre 1998, une sonde spatiale la NASA lance une sonde spatiale en direction de la plan√®te Mars afin d‚Äô√©tudier l‚Äôatmosph√®re et le climat de Mars\nLe co√ªt total de cette sonde √† √©t√© √©valu√© √† $125M\nL‚Äôobjectif √©tant de ramener des mesures et des donn√©es scientifiques sur l‚Äôatmosph√®re et le climat de la plan√®te.\nMais en Septembre 1999 au moment o√π la sonde devait entrer en orbite avec la plan√®te, ils perdent tout contact avec l‚Äôappareil.\nEn fait l‚Äô√©quipe de navigation du Jet Propulsion Laboratory (JPL) a utilis√© le syst√®me m√©trique pour tous ses calculs.\nAlors que Lockheed Martin Astronautics √† Denver, dans le Colorado, qui a con√ßu et construit l‚Äôengin spatial, a fourni des donn√©es d‚Äôacc√©l√©ration en syst√®me anglais.\nLes ing√©nieurs du Jet Propulsion Lab de la NASA ont suppos√© que la conversion avait √©t√© effectu√©e, car c‚Äô√©tait une pratique courante, mais ce n‚Äô√©tait pas le cas.\nCela a entra√Æn√© des erreurs de trajectoire pour la sonde spatiale, l‚Äôenvoyant trop pr√®s de l‚Äôatmosph√®re de la plan√®te et provoquant sa destruction.\nVoil√† comment une simple erreur d‚Äôunit√© de mesure peut conduire √† un vrai d√©sastre et √† une perte financi√®re cons√©quente."
  },
  {
    "objectID": "blog/post_14.html",
    "href": "blog/post_14.html",
    "title": "Data in PR vs Data in Reality",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_datamanagement-dataquality-digitaltransformation-activity-7041700222892167169-P0JI?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 15 Mar 2023\n\nData Management: PR Talk vs.¬†Reality\nEver noticed how sometimes companies boast about their data-driven strategies in public relations, but behind the scenes, their data management practices tell a different story?\nIn PR: ‚ÄúThanks to our successful digital transformation, we are a data-driven company leveraging AI to innovate and grow.‚Äù\nIn Reality: ‚ÄúWe don‚Äôt need data quality management, our data is already good. And why do we need to document our data?‚Äù\nI believe the issue stems from a lack of clarity. Being data-driven or achieving digital transformation is not an end in itself; it‚Äôs merely a means (for all my marketing folks out there: it‚Äôs a feature, not a benefit).\nFor me, the real questions should be:\n\nWhat does your company want to accomplish?\nHow can data help move towards those goals?\n\nFrom there start small and iterate\nBut if you chase buzzwords, that‚Äôs what you‚Äôll get in the end‚Ä¶ buzzwords."
  },
  {
    "objectID": "blog/post_12.html",
    "href": "blog/post_12.html",
    "title": "Data VS Information",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-information-debate-activity-7037779968621260800-pVY7?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 01 Mar 2023\n\nMost data pros agree on the fact that data is not the same as information.\nBut are they really that different ?\nLet‚Äôs take a look at commonly used definitions for both concepts :\n\nData: Raw, unorganized facts that need to be processed.\nInformation: When data is processed, organized, structured or presented in a given context to make it useful.\n\nAt first sight those definitions that take roots from the DIKW pyramid, sounds OK but i think there is a caveat‚Ä¶\nWhen most people, even us data pros, talk about data, 90% of the time, we talk about structured data\n(the percentage is a wild guess but you get my point)\nAnd if it‚Äôs structured it means it must have some context.\nThink of a spreadsheet table, you would have the colum name and row number for each ‚Äúdata‚Äù\nSo isn‚Äôt it an information then‚Ä¶. ?\nThat would mean that only unstructured data are real data and structured data are information ?\nAlso, can information originate from something other than data ?\nOutside of the industry, people don‚Äôt know the difference and just want useful data/information.\nWho would care about random figures, without any context, that are unorganized and meaningless, right?\nSo are they really different ? Does it matter that much ?\n\nAn interesting exchange in the comment :\n\n‚ÄúMy thoughts on information derived from data come from questions asked of the cleaning process. E.g. how do we still keep inputting bad data or data out of limits, where is this data from, who logged it? I think information from other sources is possible, maybe thought experiments i.e., set up the experiment prior to obtaining data, informs the strategy for the collection process. Also, no data in itself informs information.‚Äù\n‚ÄúFrom the cleaning angle it make more sense to me. I would go for something like information help reducing uncertainty/making decision and data can be or not be an information depending on the question/decision‚Äù"
  },
  {
    "objectID": "blog/post_10.html",
    "href": "blog/post_10.html",
    "title": "What NOT to do for improving data quality",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-datamanagement-digital-activity-7034069227783249920-JuHr?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 22 Feb 2023\n\nHey, it is well-known that data quality is not a big deal, right‚Ä¶ ?\nSo let‚Äôs look at 6 tips together to make sure it doesn‚Äôt improve :\n\nTreat data quality as a technical problem only\n\n\nUse only technical solutions to improve it (e.g., software, probabilistic controls, etc.).\nDo not involve business SMEs (data producers, data consumers) to ensure that data quality management is as far from business priorities as possible and that they do not understand it.\n\n\nDo not use common and clear guidelines for data quality management\n\n\nStress everyone in the company about bad data quality and that it‚Äôs their job to improve it.\nDo not define any systematic process for data quality management or any guidelines.\n\n\nFocus only on theoritical aspects\n\n\nMake sure to have all data quality dimensions quoted in the literature (60+) covered by your data quality process.\nMake your process documentation highly complicated and full of jargon. This way, nobody will be able to contribute to it or understand the meanings and methodology of indicators.\n\n\nPerform only data corrections, root cause don‚Äôt matters that much\n\n\nFocus all effort on data correction and firefighting quality issues where the ‚Äúsymptoms‚Äù occur.\nForget about root cause analysis and a holistic view of why we have an issue. It‚Äôs completely unnecessary.\n\n\nTreat all quality issue as the same no matter the business impacts\n\n\nThe real business impact of quality issues is irrelevant; make sure not to prioritize the high impact ones.\nIn fact, to save time, you can just not assess the impact of quality issues and use instead the ‚Äúwet-finger‚Äù prioritization technique\n\n\nLaunch isolated data quality projects\n\n\nBy avoiding a common and continuous approach, you ensure information loss and prevent follow-through of the issues previously identified.\nIt also helps to create or reinforce existing silos in the company, which is always a good thing, especially when it comes to data."
  },
  {
    "objectID": "blog/post_0.html",
    "href": "blog/post_0.html",
    "title": "Data management buzzword",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-datacatalog-datagoverance-activity-7008705261292896257-qcX-?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 14 Dec 2022\n\nWe all have heard about hashtag#dataquality, hashtag#datacatalog or hashtag#datagoverance. Are they hashtag#buzzwords for you ? Or do you know clearly what they mean in your specific company context ?\nThe n¬∞1 step of any data-related initiatives is to have clarity on what we actually want to accomplish. Just saying we are going to create a data dictionary or we are going to do data quality is not enough.\nAny data related terms can be understood differently depending on the audience. For instance the term data quality can refer to the level of data quality of a given data object, the complete process of managing data quality or a ‚Äúone-shot‚Äù data quality investigation. This might create confusion if the term itself and the expected outcomes associated with it are not well defined.\nAs an example, one of my customer wanted to implement a data catalog solution though their maturity on hashtag#datamanagement and hashtag#datagovernance was very low (they didn‚Äôt had any type of governance in place at that time).\nDue to no governance and no business data owner involvement, they wanted to focus the data catalog on documenting only the technical aspects (database(s), table(s), SQL queries, etc)\nPurpose of a data catalog is to document company data so that any collaborator can easily know what it means, how to interpret it, where he can access it and who is responsible for it.\nThe focus should be on documenting business terms, ownership, business rules, policies, etc by starting from a ‚Äútop-down‚Äù approach (top being business/natural language, bottom technical). Only once the business aspects are mastered, then the technical information becomes useful as they can be placed into a business context.\nMain takeaway here is that if you lack hashtag#clarity for your data project(s), you should work this out first !\n\nOriginal picture from Michelle Tresemer - Unsplash"
  },
  {
    "objectID": "blog/post_1.html",
    "href": "blog/post_1.html",
    "title": "Data quality rules",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-dataquality-datamanagement-activity-7010884645273673728-YOrQ?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 20 Dec 2022\n\nDo you struggle with data quality rules ? Let me share with you how i deal with definition of data quality rules :\nFirst, let‚Äôs think about hashtag#data as a digital representation of a ‚Äúthing‚Äù. In a company context those ‚Äúthings‚Äù are usually objects that are being manipulated during the business processes of the company (i.e : Customer, Location, Material, Invoices, etc).\nThose ‚Äúthings‚Äù have different characteristics being represented by attributes (if we stay with Customer example the attributes could be First Name, Last Name, Address, etc).\nA high hashtag#dataquality means the business data object(s), stored in our information systems are :\n\n‚úÖ An accurate representation of those ‚Äúthings‚Äù\n‚úÖ Fit for the usage that we make of it as part of the business processes.\n\nTo improve data quality, we need to define what are the expectations for the characteristics of those business objects for them to be as such.\nSimply put, it means that we need to define the business rules of our objects and to measure through data quality indicators if our business objects are indeed compliant with those rules or not (on paper it sounds trivial doesn‚Äôt it ? üòÅ)\nLet‚Äôs make an example with the Invoice business objects of a retail clothing company :\nBy definition an invoice should have some mandatory characteristics (Issuer Name, Goods delivered and prices, VAT Number, etc), if an invoice doesn‚Äôt have one of those, it‚Äôs not a valid invoice ‚û° Business Rules n¬∞1\nAn invoice should be always associated to a Customer ‚û° Business Rules n¬∞2\nThe list goes on ‚Ä¶.\nBased on those business rules, you define your DQ indicators (rate of incomplete invoice, rate of invoice not associated to a customer). Collection of all those rules with associated indicators is what i call a data quality standards and should be what‚Äôs monitored on regular basis by your data quality management process.\n\nOriginal picture from Ben White on Unsplash"
  },
  {
    "objectID": "blog/post_11.html",
    "href": "blog/post_11.html",
    "title": "How to explain the value of data to your colleagues",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-analytics-ai-activity-7036735231785132032-JzHv?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 01 Mar 2023\n\nDo you struggle to explain the value of data to your boss and co-workers? ü§î\nAs data professionals, we can get caught up in our own expertise and forget about the perspective of ‚Äúnon-data‚Äù folks.\nTo help bridge the gap, I‚Äôve created a visual to show how data can tie into business outcomes.\nThere are three significant ways that data can impact a company (assuming you‚Äôre not a tech company):\n\nBetter decision-making (analytics): The ability to extract trustworthy information on your market and operations for business decisions.\nAutomation (AI): Innovation and operational improvement through automation for more value with less effort.\nAvoiding operational disasters (data quality): Bad data quality can cause disasters like NASA‚Äôs lost Mars Orbiter worth ‚Ç¨125M due to a unit of measure error ! üò±\n\n(The NASA disaster will be the topic of an upcoming post, so make sure to follow me if you don‚Äôt want to miss it üòâ)\nAll of these require the right peoples, tools, and processes to manage data end-to-end in your company.\nEasy peasy, right? üòá"
  },
  {
    "objectID": "blog/post_13.html",
    "href": "blog/post_13.html",
    "title": "Data management jargon",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-data-learning-activity-7039189646546718721-UK-H?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 08 Mar 2023\n\nDo you ever feel like you‚Äôre struggling to explain the data jargon to your coworkers? ü§Ø\nTrust me, I know what you feel!\nSo let me share with you, the definition I use to explain data quality to a non-data audience:\nFirst, you can think of data as a digital twin of a real thing.\nAs an example, customer data in your CRM are the digital twins of your ‚Äúreal‚Äù customers.\nData quality is about how accurate that digital twin is compared to the real thing‚Ä¶.\nBut here‚Äôs the thing: quality is a subjective concept.\nLet‚Äôs take a pair of shoes‚Ä¶ What makes them high-quality?\nIt depends on who‚Äôs wearing them and what they‚Äôre wearing them for, right?\nWell, it‚Äôs the same with data! Quality will depend a lot on the usage.\nTo keep with the shoe analogy, managing data quality is a lot like managing quality in a shoe factory. It requires to :\n\nDefine quality requirements\nRegularly check that the data meets your expectations\nAddress any complaints from consumers\nInvestigate the causes of quality issues.\n\nIt‚Äôs not always fun, but it‚Äôs definitely necessary !\nAre your data as good as stilettos on the rugby field or do you have your data cleats on? üòÇ"
  },
  {
    "objectID": "blog/post_15.html",
    "href": "blog/post_15.html",
    "title": "Persuade your boss/team about the value of your projects",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_est-ce-que-tu-gal%C3%A8res-%C3%A0-convaincre-ton-boss-activity-7044260184516362241-CePx?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 22 Mar 2023\n\nHaving trouble persuading your boss and team about the value of your data projects?\nI believe it‚Äôs a situation most of data pros have experienced at some point.\nIn such scenarios, my tactic is to clearly show how data can influence your boss‚Äôs objectives and your organization‚Äôs aspirations.\nIt‚Äôs great to have a quantifiable business case (my project will generate X‚Ç¨ in revenue / cut X‚Ç¨ in costs), but it isn‚Äôt always straightforward to measure.\nEspecially for topics such as data governance, data quality management or data catalog\nAs an alternative, consider the qualitative side; I enjoy using simple visuals like cause-and-effect charts.\nBy itself it may not secure a ‚Ç¨1M budget, but if you can clearly establish the connection between data and management‚Äôs goals,\nIt will make everything else easier!\nHowever, if the purpose remains unclear, progress will be considerably more challenging.\nAs data professionals, I think it‚Äôs our responsibility to effectively convey the added value of our efforts to our colleagues.\nDo you employ other strategies for promoting data internally? Share your thoughts in the comments!"
  },
  {
    "objectID": "blog/post_18.html",
    "href": "blog/post_18.html",
    "title": "La data gouvernance comme les antibiotiques, c‚Äôest pas automatique !",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_datagovernance-data-digital-activity-7051111845520109568-MlCZ?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 10 Apr 2023\n\nLa gouvernance des donn√©es, c‚Äôest comme les antibiotiques‚Ä¶ ce n‚Äôest pas automatique !\nAs-tu d√©j√† pass√© des heures √† mettre en place une gouvernance des donn√©es et √† organiser d‚Äôinterminables ‚Äúdata governance council‚Äù‚Ä¶\nPour finalement te rendre compte que peu de progr√®s concrets sont r√©alis√©s ?\nLa cl√© de la mise en place d‚Äôune gouvernance des donn√©es, c‚Äôest la clart√©.\nSans but clair, la gouvernance des donn√©es devient simplement une autre case √† cocher.\nEt il est peu probable qu‚Äôelle apporte une plus-value significative √† ton organisation et risque plus d‚Äô√™tre une perte de temps et d‚Äô√©nergie.\nOK, mais alors, c‚Äôest quoi la solution ?\nMon approche consiste √† consid√©rer la gouvernance des donn√©es comme un r√©seau !\nUn r√©seau sur lequel on va s‚Äôappuyer pour prendre des d√©cisions, transmettre et r√©cup√©rer des informations et faire ex√©cuter nos diff√©rentes initiatives dans les diff√©rents domaines (Finance, Marketing, RH, etc).\nLe plus important est donc d‚Äôidentifier les bons acteurs et d‚Äôanimer ce r√©seau afin d‚Äôentretenir une dynamique collaborative et saine.\nLe processus et le cadre sont √©videmment √† prendre en compte, mais ils passent au second plan par rapport au groupe et aux individus.\nPour r√©sumer simplement, je dirais que :\nBon processus de gouvernance + mauvaise dynamique de groupe = mauvaise gouvernance\nProcessus de gouvernance moyen + bonne dynamique de groupe = bonne gouvernance"
  },
  {
    "objectID": "blog/post_2.html",
    "href": "blog/post_2.html",
    "title": "Data quality target level",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-businessrules-data-activity-7013428267151970304-iMC-?utm_source=share&utm_medium=member_desktop\nDate originale de publication :\n\nüó£ : ‚ÄúHow do you define data quality target levels ?‚Äù üó£ : ‚ÄúWell‚Ä¶ you don‚Äôt !‚Äù\nI do not recommend to set goals in terms of hashtag#dataquality levels, unless you are already advanced in your data quality management process.\nThe main 3 reasons why i don‚Äôt recommend setting goals are ‚¨á\n\n‚õî Not enough business clarity on your data quality indicators. You probably don‚Äôt have enough understanding yet on the hashtag#businessrules that govern your data objects, so your data quality indicators might not be that significant in terms of quality (accurate representation and fit-for-purpose in terms of business processes)\n‚õî No full picture on all your current data quality issues and their business impact (due to the point above), so no precise idea of their relative priority.\n‚õî No complete understanding of the root causes of those issues. If this the case, the effort required to resolve the issues remains unknown, neither if it‚Äôs actually possible or a good trade in terms of cost/benefits.\n\nIf all those aspects are covered within systematic, iterative and ‚Äúevidence-based‚Äù data quality management process then only i would start setting goals in terms of what level of data quality for a given dataset/data object i want to achieve over a period.\nIn my opinion, a better way to measure progress in the beginning of your data quality journey would be the coverage of the data quality management in terms of business scope and/or percentage of data quality issues resolved over a period.\nIn a way it‚Äôs like dieting, when you start you do not have direct control over the final outcomes (how much weight you lose/gain) but you have control over the process (sticking to it over time) and that is where the improvement comes. After a while, once you know your body well and how you react to diet, then you can set more realistic goals in terms of weight gain/loss over the next months.\nWhat do you think about this post ? If you liked it feel free to like it and share it ! If you have any comments, questions or suggestions i would really like to have your opinion in the comments\n\nOriginal picture from Andrea Piacquadio on Pexels"
  },
  {
    "objectID": "blog/post_21.html",
    "href": "blog/post_21.html",
    "title": "Dimensions de la qualit√©s de donn√©es",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-data-qualitaezdedonnaezes-activity-7052528403819683841-S04l?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Fri, 14 Apr 2023\n\nLes DIMENSIONS de la DATA QUALITY sont-elles r√©ellement UTILES ?\nJe veux dire‚Ä¶, est-ce tu peux honn√™tement me dire la diff√©rence entre la pr√©cision, la coh√©rence et la conformit√© sans regarder dans le DAMA ?\nSi une donn√©e est coh√©rente‚Ä¶ c‚Äôest qu‚Äôelle conforme √† une r√®gle non ?\nEt si elle est pr√©cise c‚Äôest qu‚Äôelle est conforme avec la r√©alit√© ? ü§®\nJe ne dit pas que les dimensions sont compl√®tement inutile mais plut√¥t que ce n‚Äôest pas le seul paradigme pour d√©finir des indicateurs de qualit√©\nElles sont souvent m√™me une source de confusion (selon o√π on regarde, il y a entre 5 et 60 dimensions‚Ä¶ üò±)\nJe pr√©f√®re penser les r√®gles de qualit√© de donn√©es comme le reflet des r√®gles m√©tiers, tes indicateurs de qualit√© de donn√©es devraient donc mesurer si tes donn√©es respectent les r√®gles m√©tiers.\nEn revanche si tu te base uniquement sur les dimensions pour d√©finir des indicateurs de qualit√© (ex : Taux de pr√©cision ou taux de coh√©rence) tu risque de cr√©er de la confusion sur la signification de l‚Äôindicateur.\nLe souci √©tant que l‚Äôinterpr√©tation de ces dimensions va grandement d√©pendre de ton audience, du contexte, etc\nJe pr√©f√®re savoir et communiquer ce que l‚Äôindicateur mesure en termes simples, plut√¥t que de savoir qu‚Äôil se rapporte √† la dimensions X ou Y‚Ä¶.\nLes indicateurs de qualit√©s de donn√©es doivent √™tre factuel, pr√©cis et bas√© sur des r√®gles m√©tiers et ne peuvent donc pas s‚Äôappuyer uniquement sur les dimensions de la qualit√© de donn√©es\nEgalement, si tu peux rendre tes indicateurs compr√©hensibles par les gens qui n‚Äôont pas lu le DAMA √ßa ne peut-√™tre qu‚Äôun plus pour aider √† la diffusion et la compr√©hension de la d√©marche qualit√© √† tes coll√®gues ‚Äúnon-data‚Äù\nPour illustrer mon propos, je te propose cet exemple :\n\nLe taux de raisonnabilit√© du r√©f√©rentiel Client ne parlera probablement √† personne\nLe taux de facture non-associ√©es √† un client valide, en revanche est beaucoup plus compr√©hensible, m√™me pour un non-initi√©"
  },
  {
    "objectID": "blog/post_24.html",
    "href": "blog/post_24.html",
    "title": "Strat√©gie data : Objectifs vs Moyens",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-strategy-activity-7056514688972390400-v0D2?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 25 Apr 2023\n\nTu sais c‚Äôest quoi le point COMMUN de la plupart des MAUVAISES strat√©gie data ?\nElles sont orient√©es principalement sur la technologie‚Ä¶.\nUne bonne strat√©gie data devrait √™tre fix√©e sur les priorit√©s et les enjeux de la soci√©t√©\nEn se basant sur des cas d‚Äôusage concrets et si possible quantifiable\nEt pas sur la derni√®re techno ou concept √† la mode\nCe serait comme dire √† quelqu‚Äôun dont l‚Äôobjectif est de se remettre en forme, de construire une salle de sport dans son garage\nC‚Äôest pas inutile en soi mais c‚Äôest pas √ßa qui va la rapprocher le plus de son objectif\nIl faut √©videmment mettre √ßa en perspective et ne pas tomber dans un biais uniquement court terme\nMais en se basant sur la finalit√© r√©elle, pas les moyens employ√©s"
  },
  {
    "objectID": "blog/post_26.html",
    "href": "blog/post_26.html",
    "title": "C‚Äôest quoi un data manager ?",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-datamanagement-datamanager-activity-7057239484794302464-PhiJ?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Thu, 27 Apr 2023\n\nAu fait, c‚Äôest quoi un ‚Äúdata manager‚Äù ? ü§î\nLaisse-moi te pr√©senter ce r√¥le, un peu moins connu du grand public mais qui est pourtant pr√©sent dans toutes la plupart des entreprises avec une strat√©gie data !\nParfois appel√© aussi data governance manager ou data quality manager, le data manager est responsable de la gestion des donn√©es de l‚Äôentreprise.\n‚ÄúEt c‚Äôest quoi la gestion des donn√©es de l‚Äôentreprise ?‚Äù\nDoucement j‚Äôy viens‚Ä¶.\nLe but de la gestion de donn√©es c‚Äôest de faire en sorte que l‚Äôentreprise tire le meilleur parti de ses donn√©es en s‚Äôassurant qu‚Äôelles soit :\n\nde bonne qualit√©\naccessible aux bonne personnes\nau bons endroits\net utilis√©es de mani√®re optimales\n\nPour que ce soit plus concret voil√† une liste de t√¢ches qu‚Äôun data manager peut-√™tre amener √† faire :\n\nD√©finir le processus de cr√©ation/modification/archivage d‚Äôune donn√©es dans un r√©f√©rentiel\nEffectuer un audit de la qualit√© de donn√©es\nMettre en place une d√©marche d‚Äôam√©lioration continue de la qualit√© des donn√©es\nD√©finir les r√¥les et responsabilit√© autour des donn√©es (qui est responsable de quoi pour de quelle donn√©es)\nAnimer un r√©seau de r√©f√©rent data au sein des diff√©rents domaines m√©tiers\nDocumenter le mod√®le de donn√©es conceptuel\nDocumenter les d√©finitions, r√®gles m√©tiers, etc associ√©es au donn√©es\n\nC‚Äôest un acteur cl√© de la strat√©gie data d‚Äôune entreprise car il va faciliter et d√©bloquer la cr√©ation de valeur par les autres acteurs de la cha√Æne (data engineer, data analyst, data scientist, etc)\nSans data manager, les t√¢ches qui lui sont normalement affect√©es se retrouvent dispers√©es sur les autres acteurs qui doivent les g√©rer en plus de leur job‚Ä¶\nPas top comme situation !"
  },
  {
    "objectID": "blog/post_29.html",
    "href": "blog/post_29.html",
    "title": "L‚Äôimportance de la clart√© dans les projets data",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-gestiondeprojet-datamanagement-activity-7059413811090345984-P3PD?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 03 May 2023\n\nPlusieurs MOIS et des dizaines de K‚Ç¨ d√©pens√© pour RIEN ! üò±\nJe vais te raconter une histoire VRAIE qui m‚Äôest arriv√©e sur un PROJET DATA qui n‚Äôaurait jamais d√ª √™tre lanc√©‚Ä¶.\nJe travaillais sur la gouvernance et la qualit√© des donn√©es pour une grosse soci√©t√©\nEt avant m√™me que je prenne mon poste, un projet de cr√©ation d‚Äôun r√©f√©rentiel pour une nouvelle donn√©e avait √©t√© lanc√©.\nL‚Äô√©quipe projet avait pass√©e environ 1 an √† essayer de naviguer entre les conflits et la politique interne de l‚Äôentreprise (la donn√©es en question √©tant un sujet sensible) sans r√©el progr√®s\nOn avait m√™me pas de d√©finition claire de pour cette nouvelle donn√©e\nAutant te dire que le r√©f√©rentiel n‚Äô√©tait toujours pas pr√™t de voir le jour‚Ä¶.\nPour d√©bloquer la situation, un atelier √† donc √©t√© organis√© par le chef de projet lors duquel les questions suivantes ont √©t√© pos√©es :\n‚Ä¢ Pourquoi est-ce qu‚Äôon fait ce nouveau r√©f√©rentiel en fait ?\n‚Ä¢ C‚Äôest quoi cette nouvelle donn√©e ?\nIl s‚Äôest av√©r√© que cette ‚Äúnouvelle‚Äù donn√©e √©tait en r√©alit√© quasi-identique √† une autre d√©j√† existante dans un autre r√©f√©rentiel‚Ä¶. üòÖ\nEt que ce projet de nouveau r√©f√©rentiel avait √©t√© lanc√© uniquement dans le but de r√©pondre √† une question pos√©e par un top exec‚Äô il y a de √ßa plus d‚Äô1 an‚Ä¶.\nApr√®s quelques autres r√©unions et en impliquant les bonnes personnes, le probl√®me √©tait quasi-r√©solu.\nEn utilisant les donn√©es d√©j√† existantes on pouvait r√©pondre √† 95% de la question pos√©e‚Ä¶\nSans projet, sans budget, sans une arm√©e d‚Äôexternes, et sans d√©lai‚Ä¶.\nVoil√† pourquoi je pense qu‚Äôil est important d‚Äôavoir de la clart√© sur POURQUOI on fait ce que l‚Äôon fait\nAutrement on peut vite se perdre dans le COMMENT, perdre de vue la finalit√© et finir par faire fausse route"
  },
  {
    "objectID": "blog/post_30.html",
    "href": "blog/post_30.html",
    "title": "Contr√¥le de qualit√© de donn√©es d√©terministe vs probabiliste",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_contr%C3%B4le-de-qualit%C3%A9-de-donn%C3%A9es-d%C3%A9terministe-activity-7060138562465280000-QDzQ?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Fri, 05 May 2023\n\nContr√¥le de qualit√© de donn√©es D√âTERMINISTE vs PROBABILISTE‚Ä¶\nEst-ce que tu connais les diff√©rences entre ces deux types de contr√¥le ?\nJe te propose cette petite infographie qui r√©sume mes connaissances sur le sujet ‚¨áÔ∏è\nContr√¥le d√©terministe (bas√© sur des r√®gles et une logique conditionnelle) :\n\nQuestion : Est-ce que cette donn√©e est une anomalie ?\nAvantages : Facile √† interpr√©ter\nInconv√©nients : Les r√®gles doivent √™tre d√©finis √† la main et n√©cessitent une certaine connaissance du domaine m√©tier\n\nContr√¥le probabiliste (d√©tection d‚Äôanomalies, etc) :\n\nQuestion : Est-ce qu‚Äôil est probable que cette donn√©es soit une anomalie ?\nAvantages : Ne n√©cessite pas des r√®gles formelles\nInconv√©nients : Interpr√©tabilit√© plus d√©licate (faux positif/faux n√©gatif), th√©orie du monde clos et d√©pendance au niveau de qualit√© initiale\n\n√âvidemment les deux approches ne sont pas oppos√©es et peuvent se compl√©ter\nMais dans un souci de simplicit√©, je pr√©f√®re me concentrer en premier lieu sur les contr√¥les d√©terministe\nQui me permettent de transitionner plus facilement vers les autres √©tapes de la d√©marche qualit√©\nEn revanche, si je suis sur une d√©marche qualit√© d√©j√† rod√©e et que je veux aller un peu plus loin, dans ce cas les contr√¥les probabilistes sont tr√®s int√©ressants (notamment sur du d√©doublonnage)."
  },
  {
    "objectID": "blog/post_32.html",
    "href": "blog/post_32.html",
    "title": "4 livres √† lire sur la gestion de la qualit√© de donn√©es",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_4-ouvrages-%C3%A0-lire-absolument-si-tu-tint%C3%A9resse-activity-7065211992893972480-GEF4?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Fri, 19 May 2023\n\n4 ouvrages √† LIRE ABSOLUMENT si tu t‚Äôint√©resse √† la DATA QUALITY :\n‚Ä¢ Danette McGilvray - Executing Data Quality Projects: Ten Steps to Quality Data and Trusted Information (2008)\nUn classique, le livre est tr√®s complet aborde la qualit√© de donn√©es sous un angle pratique. Parfait si tu veut comprendre et mettre rapidement en place un projet d‚Äôam√©lioration de la qualit√© de donn√©es\n‚Ä¢ Jack E. Olson - Data Quality: The Accuracy Dimension (2003)\nTr√®s bon livre, tr√®s complet aussi. J‚Äôai trouv√© le chapitre sur le business case tr√®s pertinent, on sent que l‚Äôauteur √† une grosse exp√©rience du sujet.\n‚Ä¢ Lowell Fryman, Gregory Lampshire, Dan Meers: The Data and Analytics Playbook: Proven Methods for Governed Data and Analytic Quality (2016)\nUn peu plus orient√© data governance, con√ßu comme ‚Äúun playbook‚Äù pour un leader data pourrait suivr, le livre d√©crit de fa√ßon int√©ressante certaine des situations ‚Äúpolitiques‚Äù autour de la governance des donn√©es\n‚Ä¢ Laura Sebastian-Coleman - Meeting the Challenges of Data Quality Management (2022)\nPlus r√©cent que les pr√©c√®dents, l‚Äôouvrage est encore plus complet puisqu‚Äôil aborde aussi d‚Äôautres th√©matiques comme la strat√©gie ou la culture data."
  },
  {
    "objectID": "blog/post_34.html",
    "href": "blog/post_34.html",
    "title": "3 d√©finitions pour mieux g√©rer ses donn√©es d‚Äôentreprises",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-datamanagement-datagovernance-activity-7067023930263248896-Q3tB?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 24 May 2023\n\n3 d√©finitions SIMPLES pour POSER LES BASES quand tu parle DATA\nC‚Äôest pas toujours facile de parler data\nEntre le data mesh, la data fabric, la data observability ou encore la data gouvernance‚Ä¶.\nOn peut vite s‚Äôy m√©langer les pinceaux, m√™me pour les pros !\nImagine quelqu‚Äôun qui n‚Äôest pas du domaine‚Ä¶\nAlors pour partir sur de bonnes base quand tu parle data avec quelqu‚Äôun qui n‚Äôest pas familier avec la terminologie\nJe te propose ces trois d√©finitions :\n‚Ä¢ Donn√©es : Repr√©sentation digitale (√ß√†d dans un SI) d‚Äôun objet ou d‚Äôun √©v√©nement r√©el\n‚Ä¢ Attribut : Repr√©sentation digitale d‚Äôune caract√©ristiques d‚Äôint√©r√™t de notre objet/√©v√®nement\n‚Ä¢ Mod√®le de donn√©es : Ensemble des attributs d‚Äôun objet/√©v√©nement"
  },
  {
    "objectID": "blog/post_36.html",
    "href": "blog/post_36.html",
    "title": "4 frameworks de gestion de la qualit√© de donn√©es √† connaitre !",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-datamanagement-data-activity-7069198262502617088-IW8t?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 30 May 2023\n\n3 causes possibles de doublons dans un jeu de donn√©es :\n‚Ä¢ Int√©gration de plusieurs sources sans r√©conciliation :\nSi l‚Äôon int√®gre des r√©f√©rentiels clients provenant de diff√©rentes sources dans un entrep√¥t de donn√©es sans les r√©concilier entre eux, il est fort probable que des doublons se forment.\n‚Ä¢ Pas de v√©rification lors de la cr√©ation :\nL‚Äô√©tape de cr√©ation/saisie des donn√©es est cruciale. Un contr√¥le lors de la saisie pour pr√©venir la cr√©ation de doublons dans le r√©f√©rentiel peut √©viter de nombreuses anomalies !\n‚Ä¢ Pas d‚Äôidentifiant unique :\nIl est surprenant que cela existe encore en 2023‚Ä¶ Cependant, il est possible que certains syst√®mes ou processus ne g√©n√®rent pas d‚Äôidentifiant unique pour les diff√©rents objets/√©v√©nements utilis√©s, ou qu‚Äôils les g√®rent mal, ce qui contribue aux causes possibles de duplication."
  },
  {
    "objectID": "blog/post_38.html",
    "href": "blog/post_38.html",
    "title": "3 m√©thodes pour calculer un indice de qualit√© des donn√©es",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-datagovernance-data-activity-7070285435175858176-2WwW?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Fri, 02 Jun 2023\n\n3 METHODES pour calculer un INDICE de DATA QUALITY !\nSi tu t‚Äôint√©resses √† la data quality, tu vas peut-√™tre vouloir d√©finir un indice de qualit√©‚Ä¶\nC‚Äôest une bonne fa√ßon d‚Äôagr√©ger les diff√©rents indicateurs de qualit√© pour avoir une id√©e de la qualit√© globale\nJe vais te partager 3 m√©thodes que j‚Äôutilise pour d√©finir et calculer un indice de data quality\nOn va partir du postulat que tes indicateurs de qualit√© sont exprim√©s en % du nombre d‚Äôentr√©es totales d‚Äôun jeu de donn√©es\n‚Ä¢ Moyenne des indicateurs (equi-pond√©ration)\nFacile, tu fais la somme des indicateurs de qualit√© et tu divises par le nombre d‚Äôindicateurs de qualit√©\nProbl√®me : Toutes les anomalies ne se valent pas\n‚Ä¢ Moyenne pond√©r√©e des indicateurs\nCette fois on va assigner un poids √† chaque indicateur pour pond√©rer le r√©sultat, permettant de refl√©ter son importance relative dans l‚Äôindice\nProbl√®me : D√©finition des poids subjective\n‚Ä¢ % d‚Äôentr√©es sans anomalies\nOn va simplement faire le % des entr√©es qui passent tous les contr√¥les.\nC‚Äôest personnellement ma pr√©f√©r√©e car elle refl√®te le mieux ma vision de la qualit√© de donn√©es.\nSi on part du principe que le standard de qualit√© = d√©finition de qualit√©, cette m√©thode nous donne le % le plus repr√©sentatif.\nL‚Äôinconv√©nient c‚Äôest qu‚Äôelle reste aveugle par rapport √† l‚Äôimportance relative des diff√©rents contr√¥les‚Ä¶"
  },
  {
    "objectID": "blog/post_4.html",
    "href": "blog/post_4.html",
    "title": "Data quality management process",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-quality-management-activity-7018491937175306241-AtNb?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 10 Jan 2023\n\nLet me explain the process I use with my clients to manage their data quality üëá\nüìú Define initial standards for monitoring hashtag#dataquality\n\nDocument business rules and derive associated data quality indicators\nDefine monitoring methodology (frequency, queries used, etc.)\n\nüëÄ Start monitoring\n\nConduct initial data quality monitoring based on the newly defined standards\nIdentify current data quality issues (non-compliance with one or more business rules)\n\nüß† Investigate root causes and effort for data correction\n\nAnalyze the data quality issues to understand what the root cause(s) are and what effort is required to correct the data affected by them\n\nüó£Ô∏è Communicate findings with the business and establish priorities\n\nShare your findings with business stakeholders and determine the criticality of the issue based on business impact\nDetermine priority based on cost (effort required to correct the data and root cause) and benefit (business impact)\n\nüîß Correct data and root cause(s)\n\nIdeally, data correction should be done in the source system\nDepending on the context (legacy application that cannot be updated, etc.), sometimes the correction needs to be done on the fly between the source and the data warehouse\n\nüîÑ Iterate\n\nEnsure that data consumers have the opportunity to raise issues not covered by the process\nThe quality standard should be updated after new business/quality rules are created or discovered"
  },
  {
    "objectID": "blog/post_41.html",
    "href": "blog/post_41.html",
    "title": "Valeur financi√®re d‚Äôune donn√©es",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_datavaluation-infonomics-data-activity-7072459755050422273-5P-Q?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Thu, 08 Jun 2023\n\nC‚Äôest POSSIBLE de calculer la VALEUR FINANCI√àRE d‚Äôune donn√©e ? üí∞ ü§î\nC‚Äôest ce que Douglas Laney propose dans son livre ‚ÄúInfonomics‚Äù\nNotamment avec cette notion qu‚Äôil appelle l‚ÄôEVI (Economic Value of Information)\nC‚Äôest une valeur sert √† mesurer √† quelle point cette donn√©es contribue √† la profitabilit√© d‚Äôune business unit\nLa formule ‚¨áÔ∏è\nEVI = (Chiffre d‚Äôaffaires A - Chiffre d‚Äôaffaires B - Co√ªts de gestion) * T/t\nChiffre d‚Äôaffaires A = Chiffre d‚Äôaffaires r√©alis√© en utilisant l‚Äôinformation Chiffre d‚Äôaffaires B = Chiffres d‚Äôaffaires r√©alis√© sans l‚Äôinformation (groupe contr√¥le)\nCo√ªts de gestion = L‚Äôensemble des co√ªts d‚Äôacquisition, de stockage et maintenance de la donn√©es\nT = Dur√©e de vie moyenne d‚Äôune instance de l‚Äôinformation t = Dur√©e de l‚Äôexp√©rimentation\nCette formule n√©cessite la mise en place d‚Äôune exp√©rience\nDans laquelle moins une business unit va servir de groupe contr√¥le\nEt donc ne pas utiliser l‚Äôinformation dont on cherche √† d√©terminer la valeur\nC‚Äôest aussi un indicateur ‚Äútardif‚Äù qui nous donne la diff√©rence de CA √† posteriori\nTu l‚Äôas compris, il n‚Äôest pas parfait‚Ä¶\nMais il a le m√©rite de d√©finir une formule pour valoriser les informations\nQui peut s‚Äôappliquer quelque soit l‚Äôinformation ou la soci√©t√©\nD‚Äôautres formules tel que l‚ÄôIntrinsic Value of Information ou la Cost Value of Information sont d√©crites dans son livre Infonomics (que je recommande)\nEt tu as aussi 2 cours du m√™me nom sur Coursera, qui sont accessible en auditeur libre üòâ"
  },
  {
    "objectID": "blog/post_43.html",
    "href": "blog/post_43.html",
    "title": "Meme business case quantitatif",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_mod%C3%A9liser-les-b%C3%A9n%C3%A9fices-est-un-excellent-activity-7075426797563039745-DvDm?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Fri, 16 Jun 2023\n\nMod√©liser les b√©n√©fices est un EXCELLENT moyen de cr√©er de l‚Äôint√©r√™t pour ton projet DATA.\nLe probl√®me des business cases quali‚Äô c‚Äôest qu‚Äôils peuvent para√Ætre parfois peu vraisemblables‚Ä¶\nOn se dit que si les b√©n√©fices ne sont pas mesurables, est-ce qu‚Äôils vont r√©ellement faire une diff√©rence pour l‚Äôorganisation ?\nPouvoir chiffrer les b√©n√©fices du projet (m√™me si ce n‚Äôest pas en ‚Ç¨) plus de poids et rend le business case plus cr√©dible"
  },
  {
    "objectID": "blog/post_45.html",
    "href": "blog/post_45.html",
    "title": "Valorisation des donn√©es",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataroi-datavaluation-datastrategy-activity-7079692406396268544-vaMe?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 28 Jun 2023\n\n4 approches pour valoriser une donn√©e ou une information !\n\nValorisation par les co√ªts\n\nOn va regarder ce que √ßa co√ªte de remplacer cette donn√©es en cas de perte ou les co√ªts de gestion/acquisition de cette donn√©e pour en d√©terminer la valeur\n\nValorisation intrins√®que\n\nLa valorisation intrins√®que va √©valuer la valeur de la donn√©e de fa√ßon ind√©pendante √† l‚Äôutilisation actuelle. On va d√©terminer la valeur ‚Äúabsolue‚Äù de la donn√©es en utilisant diff√©rents facteurs comme la raret√©, la couverture, la qualit√©, etc\n\nValorisation par le prix de march√©\n\nRarement possible en pratique, n√©cessite qu‚Äôil existe un march√© pour cette donn√©es et que ce march√© ‚Äúprice‚Äù la donn√©es correctement. On va ensuite utiliser le prix de march√© pour valoriser notre donn√©e\n\nValorisation par l‚Äôutilit√©\n\nOn va regarder √† quel point cette donn√©e est utile pour d√©terminer sa valeur. Le plus elle impacte positivement les enjeux d‚Äôun individus ou d‚Äôune organisation le plus elle aura de valeur"
  },
  {
    "objectID": "blog/post_47.html",
    "href": "blog/post_47.html",
    "title": "Data-as-an-asset",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-dataasset-datastrategy-activity-7081930263563264002-xtP3?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 04 Jul 2023\n\nhttps://www.linkedin.com/posts/yacine-bekka_data-dataasset-datastrategy-activity-7081930263563264002-xtP3?utm_source=share&utm_medium=member_desktop\nPasser de ‚Äúdata-as-a-cost‚Äù √† ‚Äúdata-as-an-asset‚Äù\nBeaucoup d‚Äôorganisations voient encore les donn√©es comme un centre de co√ªts‚Ä¶\nElles n‚Äôexploitent pas le ‚Äúvrai‚Äù pouvoir de la data.\nLes donn√©es servent uniquement √† soutenir le bon fonctionnement des op√©rations.\nAu mieux, un reporting, un tableau de bord ici et l√†‚Ä¶\nLa vraie valeur de la data, c‚Äôest de pouvoir l‚Äôutiliser pour pr√©dire un √©tat futur.\nDans la vie et dans les affaires, l‚Äôimmense majorit√© des d√©cisions sont prises dans un √©tat d‚Äôincertitude.\nParfois plus ou moins important‚Ä¶\nLa capacit√© √† pr√©dire le futur, m√™me de fa√ßon imparfaite, constitue un avantage, puisqu‚Äôon vient r√©duire cette incertitude.\nPar exemple, si vous pouvez pr√©dire les employ√©s susceptibles de d√©missionner.\nCela va permettre de prendre de meilleures d√©cisions op√©rationnelles et in fine :\n‚Ä¢ d‚Äôam√©liorer la r√©tention, ‚Ä¢ de diminuer les co√ªts de recrutement, ‚Ä¢ d‚Äô√©viter que des postes critiques pour l‚Äôorganisation ne restent vacants trop longtemps.\nC‚Äôest de cette fa√ßon qu‚Äôune data devient une source de profit pour l‚Äôorganisation."
  },
  {
    "objectID": "blog/post_49.html",
    "href": "blog/post_49.html",
    "title": "Carousel VEIPPP",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_valeur-esp%C3%A9r%C3%A9e-dune-information-partielle-activity-7080054792445685760-nII5?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Thu, 29 Jun 2023"
  },
  {
    "objectID": "blog/post_50.html",
    "href": "blog/post_50.html",
    "title": "Carousel VEII",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_valeur-esp%C3%A9r%C3%A9e-dune-information-imparfaite-activity-7079020492392652800-GE7B?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Mon, 26 Jun 2023"
  },
  {
    "objectID": "blog/post_52.html",
    "href": "blog/post_52.html",
    "title": "Carousel Esp√©rance et decision",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_esp%C3%A9rance-de-gain-et-prise-de-d%C3%A9cision-activity-7076800858734096384‚ÄìUAg?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 20 Jun 2023"
  },
  {
    "objectID": "blog/post_54.html",
    "href": "blog/post_54.html",
    "title": "Slides - Data quality introduction",
    "section": "",
    "text": "Vid√©o Youtube : https://www.youtube.com/watch?v=vrQiPzKHoXQ\nDate originale de publication : 22 May 2023"
  },
  {
    "objectID": "blog/post_56.html",
    "href": "blog/post_56.html",
    "title": "Slides - Standard de qualit√© des donn√©es",
    "section": "",
    "text": "Vid√©o Youtube : https://youtu.be/SIf8w5Fx6Cc\nDate originale de publication : 28 May 2023"
  },
  {
    "objectID": "blog/post_7.html",
    "href": "blog/post_7.html",
    "title": "Rules-based DQ control vs ML/AI based DQ control",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_dataquality-ai-chatgpt-activity-7023560922568777728-2HoB?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Tue, 24 Jan 2023\n\nAre you thinking about using AI for monitoring your hashtag#dataquality ? Let me share with you why it might not be the best approach\nüß† AI-based control - Question answered : Is this record likely to be anomaly, based on all other existing records ? - Pros : Doesn‚Äôt require business SME/data producer involvement - Cons : Trickier to interpret (false positive/false negative), blind to rules not inferable from the dataset, depend on the quality of data itself\nüìú Manually-defined rules based control - Question answered : Does this record comply with the predefined rule for sure ? - Pros : Easily interpretable, what you see is what you get - Cons : Rules have to be defined manually, usually by business SME/data producer\nI would usually not recommend using only AI-based control (even if you work with big data), as you would miss a lot of data quality issues and have some records flagged as issues that are perfectly accurate.\nKeep in mind also that you either develop the hashtag#AI internally (which is usually costly) or have to rely on a vendor‚Äôs solution which would be a black box (if the solution is working fine, no problem but if it‚Äôs not‚Ä¶).\nIt can be a great tool to either complement manually defined rules or to avoid the ‚Äúblank page syndrome‚Äù with business SMEs by having a set of rules to start the discussion (though other solutions exist for that purpose) but it doesn‚Äôt replace the ‚Äúold-school‚Äù way of doing things !\nA final thought, with the recent improvement in natural language models (hashtag#chatgpt), you can imagine a data quality rules inference model that would take as an input not only the data but also the documentation around this data (business process documentation, user guide for IT tools, etc).\nThis kind of solution would come with its own set of problems (confidentiality of documents, internal dev vs vendor solution, etc) but one can dream about what might be the future of data quality management‚Ä¶. Humm, what was the definition of this indicator again? üòâ"
  },
  {
    "objectID": "blog/post_9.html",
    "href": "blog/post_9.html",
    "title": "Data reliability",
    "section": "",
    "text": "Repost Linkedin : https://www.linkedin.com/posts/yacine-bekka_data-dataquality-digital-activity-7028995022901411840-COHT?utm_source=share&utm_medium=member_desktop\nDate originale de publication : Wed, 08 Feb 2023\n\nHave you already heard about ‚Äúdata reliability‚Äù ?\nI didn‚Äôt know about it either until I stumbled across it recently in my Linkedin feed so i looked into it :\n\nDo you trust your hashtag#data ?\nIf you ask them something will they tell the truth ?\nWill they be there when you need them the most ?\n\nAll of those aspects can be summarized by are your data reliable‚Ä¶ üëè\n‚ÄúI got it but isn‚Äôt it the same than hashtag#dataquality ?‚Äù üßê\nAlmost, but with a small tweak.\nJust take data quality over a period of time and voil√†‚Ä¶ you have data reliability üìà\nAlso, the term is quite popular in the data engineering community but less so with the data management folks that will usually prefer data quality.\nData reliability is as important as data quality as it impacts all processes and tools that use data.\nWith reliable data you will increase the knowledge you have on your company and your market which will lead to better business decisions.\nWith unreliable data though, you will face issues with every hashtag#digital related initiatives.\nIt will prevents your company from having efficient operations and benefiting from the latest innovations in analytics and machine learning.\nDid you like this definition ?"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Pour me contacter, il vous suffit de m‚Äôenvoyer un email √† l‚Äôadresse suivante : contact@bekkaconsulting.com. Je vous r√©pondrai dans les plus brefs d√©lais."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Portfolio & ressources",
    "section": "",
    "text": "Agent autonome pour le jeu de Yathzee\n\nAgent autonome con√ßu pour jouer contre ou assister un joueur humain au jeu de Yahtzee. Cet agent utilise l‚Äôalgorithme MCTS pour prendre des d√©cisions en temps r√©el pendant le jeu, et atteint une moyenne de 154 points par partie.\nEnti√®rement impl√©ment√© c√¥t√© client, les d√©pendances sont minimales, √©tant principalement d√©velopp√© en JavaScript ‚Äúvanilla‚Äù avec HTML/CSS (√† l‚Äôexception des graphiques, qui s‚Äôappuient sur Chart.js).\n\nPython library for statistical analysis (Work in progress)\n\nCollection de fonctions Python pour l‚Äôanalyse statistique (tests statistiques, analyse de puissance). Cette biblioth√®que n√©cessite NumPy pour le chargement des donn√©es et SciPy pour les fonctions li√©es aux lois de probabilit√©. Principalement destin√©e √† un usage personnel pour l‚Äôinstant, mais qui sait ce que l‚Äôavenir nous r√©serve‚Ä¶\n\nTS Proxy\n\nImpl√©mentation d‚Äôun serveur de proxy HTTP/HTTPS/SOCKS5 avec des fonctionnalit√©s additionnelles telles que la gestion de listes blanches/noires et des contre-mesures basiques contre les attaques DDoS."
  },
  {
    "objectID": "projects.html#software",
    "href": "projects.html#software",
    "title": "Portfolio & ressources",
    "section": "",
    "text": "Agent autonome pour le jeu de Yathzee\n\nAgent autonome con√ßu pour jouer contre ou assister un joueur humain au jeu de Yahtzee. Cet agent utilise l‚Äôalgorithme MCTS pour prendre des d√©cisions en temps r√©el pendant le jeu, et atteint une moyenne de 154 points par partie.\nEnti√®rement impl√©ment√© c√¥t√© client, les d√©pendances sont minimales, √©tant principalement d√©velopp√© en JavaScript ‚Äúvanilla‚Äù avec HTML/CSS (√† l‚Äôexception des graphiques, qui s‚Äôappuient sur Chart.js).\n\nPython library for statistical analysis (Work in progress)\n\nCollection de fonctions Python pour l‚Äôanalyse statistique (tests statistiques, analyse de puissance). Cette biblioth√®que n√©cessite NumPy pour le chargement des donn√©es et SciPy pour les fonctions li√©es aux lois de probabilit√©. Principalement destin√©e √† un usage personnel pour l‚Äôinstant, mais qui sait ce que l‚Äôavenir nous r√©serve‚Ä¶\n\nTS Proxy\n\nImpl√©mentation d‚Äôun serveur de proxy HTTP/HTTPS/SOCKS5 avec des fonctionnalit√©s additionnelles telles que la gestion de listes blanches/noires et des contre-mesures basiques contre les attaques DDoS."
  },
  {
    "objectID": "projects.html#long-form-content",
    "href": "projects.html#long-form-content",
    "title": "Portfolio & ressources",
    "section": "Long-form content",
    "text": "Long-form content\n\nRapport technique - Agent autonome pour le jeu de Yathzee\n\nRapport technique d√©taillant le fonctionnement de l‚Äôagent autonome pour le jeu de Yahtzee.\n\nGuide to Data ROI, 1st edition\n\nGuide sur la mani√®re d‚Äôestimer le ROI des projets data. Publi√© en 2023, la premi√®re √©dition n‚Äôest plus disponible publiquement en attendant la publication de la deuxi√®me √©dition, que j‚Äôesp√®re sortir bient√¥t !\nCela dit, si vous √™tes vraiment int√©ress√©, n‚Äôh√©sitez pas √† m‚Äôenvoyer un e-mail ;)"
  }
]